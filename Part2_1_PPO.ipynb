{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium gymnasium[mujoco]\n",
        "!pip install 'shimmy>=0.2.1'\n",
        "!pip install gymnasium\n",
        "!pip install -- upgrade stable - baselines3\n",
        "!pip install mujoco\n",
        "!pip install stable-baselines3\n",
        "!pip install stable-baselines3 gym tensorboard\n",
        "!apt-get install swig\n",
        "!pip install box2d\n",
        "!pip install gym[box2d]\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4OiQrY1NQsh",
        "outputId": "f6f9b31c-98e4-4db3-bee7-68b7014116c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting mujoco>=2.3.3 (from gymnasium)\n",
            "  Downloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.31.6)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium) (9.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium) (1.7.0)\n",
            "Collecting glfw (from mujoco>=2.3.3->gymnasium)\n",
            "  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium) (3.19.2)\n",
            "Installing collected packages: glfw, farama-notifications, gymnasium, mujoco\n",
            "Successfully installed farama-notifications-0.0.4 glfw-2.7.0 gymnasium-0.29.1 mujoco-3.1.6\n",
            "Collecting shimmy>=0.2.1\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=0.2.1) (1.25.2)\n",
            "Collecting gymnasium>=1.0.0a1 (from shimmy>=0.2.1)\n",
            "  Downloading gymnasium-1.0.0a2-py3-none-any.whl (954 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.3/954.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=0.2.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=0.2.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=0.2.1) (0.0.4)\n",
            "Installing collected packages: gymnasium, shimmy\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.29.1\n",
            "    Uninstalling gymnasium-0.29.1:\n",
            "      Successfully uninstalled gymnasium-0.29.1\n",
            "Successfully installed gymnasium-1.0.0a2 shimmy-2.0.0\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0a2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "\u001b[31mERROR: Invalid requirement: '-'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: mujoco in /usr/local/lib/python3.10/dist-packages (3.1.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.7.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.25.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (3.19.2)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3)\n",
            "  Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.15.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0a2\n",
            "    Uninstalling gymnasium-1.0.0a2:\n",
            "      Successfully uninstalled gymnasium-1.0.0a2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shimmy 2.0.0 requires gymnasium>=1.0.0a1, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 stable-baselines3-2.3.2\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.15.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (2,121 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.2.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.9/427.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d\n",
            "  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d: filename=Box2D-2.3.2-cp310-cp310-linux_x86_64.whl size=2367286 sha256=4749442a1e5164c9a8f9cfa079c2e2b6b527166ffefa9af60d60e0b29524122c\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/cb/be/e663f3ce9aba6580611c0febaf7cd3cf7603f87047de2a52f9\n",
            "Successfully built box2d\n",
            "Installing collected packages: box2d\n",
            "Successfully installed box2d-2.3.2\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.* (from gym[box2d])\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349116 sha256=3feeaccda68b8d94708158ef1037c3264df7e76a32a4128872ce1701a5009b9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.2.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 1: on-policy PPO model\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import VecNormalize\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def create_bipedalwalker_env(seed=None):\n",
        "    env = make_vec_env('BipedalWalker-v3', n_envs=1, seed=seed)\n",
        "    env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
        "    return env\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    seed = 0\n",
        "    set_random_seed(seed, using_cuda=True)\n",
        "\n",
        "    print(f\"Training PPO model with seed: {seed}\")\n",
        "\n",
        "    #Create the environment\n",
        "    env = create_bipedalwalker_env(seed)\n",
        "\n",
        "    #Saving\n",
        "    env.save(f'BipedalWalker-v3_vecnormalize_seed_{seed}.pkl')\n",
        "\n",
        "    #Train the agent\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, gamma=0.99, gae_lambda=0.95,\n",
        "                ent_coef=0.01, n_steps=2048, batch_size=256, clip_range=0.2, tensorboard_log=\"./tb_logs/\", seed=seed)\n",
        "\n",
        "    #Evaluate if the model reaches 300\n",
        "    callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
        "    eval_callback = EvalCallback(env, callback_on_new_best=callback_on_best, eval_freq=10000, best_model_save_path='./logs/', log_path='./logs/', deterministic=True, render=False)\n",
        "\n",
        "    #Time the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    #Training\n",
        "    total_timesteps = 2000000\n",
        "    model.learn(total_timesteps=total_timesteps, callback=eval_callback, tb_log_name=\"ppo_bipedalwalker\")\n",
        "\n",
        "    #End timing when done\n",
        "    end_time = time.time()\n",
        "\n",
        "    #Calculate time\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    #Save the model\n",
        "    model.save(f'ppo_bipedalwalker_seed_{seed}')\n",
        "\n",
        "    #Print the results\n",
        "    best_score = eval_callback.best_mean_reward\n",
        "    if best_score < 300:\n",
        "        print(f\"Best score achieved: {best_score}\")\n",
        "\n",
        "    #Reset environment\n",
        "    env.reset()\n",
        "\n",
        "    env.training = False\n",
        "    env.norm_reward = False\n",
        "\n",
        "    print(f\"Completed training PPO model for seed: {seed}\")\n",
        "    print(f\"Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    #Test model on multiple seeds\n",
        "    test_seeds = [1, 2, 3, 4, 5]\n",
        "    test_results = []\n",
        "\n",
        "    for test_seed in test_seeds:\n",
        "        set_random_seed(test_seed, using_cuda=True)\n",
        "        test_env = create_bipedalwalker_env(test_seed)\n",
        "        obs = test_env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, _ = test_env.step(action)\n",
        "            total_reward += reward\n",
        "        test_results.append(total_reward)\n",
        "        print(f\"Test seed: {test_seed}, Total reward: {total_reward}\")\n",
        "\n",
        "    print(f\"Average reward across test seeds: {np.mean(test_results)}, Std Dev: {np.std(test_results)}\")"
      ],
      "metadata": {
        "id": "hgGlvj972vmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3e853c-94b3-4b2c-adb8-e7ae9e71ba04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaminguitvoer ingekort tot de laatste 5000 regels.\u001b[0m\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 7670        |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    std                  | 4.11        |\n",
            "|    value_loss           | 0.0427      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 883          |\n",
            "|    ep_rew_mean          | 216          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 414          |\n",
            "|    iterations           | 769          |\n",
            "|    time_elapsed         | 3796         |\n",
            "|    total_timesteps      | 1574912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0105304085 |\n",
            "|    clip_fraction        | 0.0993       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.3        |\n",
            "|    explained_variance   | 0.424        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.109       |\n",
            "|    n_updates            | 7680         |\n",
            "|    policy_gradient_loss | -0.0161      |\n",
            "|    std                  | 4.11         |\n",
            "|    value_loss           | 0.0488       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 887         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 770         |\n",
            "|    time_elapsed         | 3799        |\n",
            "|    total_timesteps      | 1576960     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009642006 |\n",
            "|    clip_fraction        | 0.0829      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.909       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0775     |\n",
            "|    n_updates            | 7690        |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    std                  | 4.13        |\n",
            "|    value_loss           | 0.0917      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 886         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 771         |\n",
            "|    time_elapsed         | 3802        |\n",
            "|    total_timesteps      | 1579008     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009012014 |\n",
            "|    clip_fraction        | 0.0884      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.381       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.108      |\n",
            "|    n_updates            | 7700        |\n",
            "|    policy_gradient_loss | -0.0188     |\n",
            "|    std                  | 4.14        |\n",
            "|    value_loss           | 0.0592      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1580000, episode_reward=270.43 +/- 1.12\n",
            "Episode length: 857.80 +/- 11.69\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 858          |\n",
            "|    mean_reward          | 270          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1580000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0113559775 |\n",
            "|    clip_fraction        | 0.121        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.3        |\n",
            "|    explained_variance   | 0.42         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.105       |\n",
            "|    n_updates            | 7710         |\n",
            "|    policy_gradient_loss | -0.017       |\n",
            "|    std                  | 4.14         |\n",
            "|    value_loss           | 0.0525       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 882      |\n",
            "|    ep_rew_mean     | 216      |\n",
            "| time/              |          |\n",
            "|    fps             | 414      |\n",
            "|    iterations      | 772      |\n",
            "|    time_elapsed    | 3812     |\n",
            "|    total_timesteps | 1581056  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 884         |\n",
            "|    ep_rew_mean          | 216         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 773         |\n",
            "|    time_elapsed         | 3816        |\n",
            "|    total_timesteps      | 1583104     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007863438 |\n",
            "|    clip_fraction        | 0.0684      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.822       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.101      |\n",
            "|    n_updates            | 7720        |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    std                  | 4.17        |\n",
            "|    value_loss           | 0.164       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 884        |\n",
            "|    ep_rew_mean          | 216        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 774        |\n",
            "|    time_elapsed         | 3819       |\n",
            "|    total_timesteps      | 1585152    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01039679 |\n",
            "|    clip_fraction        | 0.0915     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -11.3      |\n",
            "|    explained_variance   | 0.0569     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.102     |\n",
            "|    n_updates            | 7730       |\n",
            "|    policy_gradient_loss | -0.0172    |\n",
            "|    std                  | 4.16       |\n",
            "|    value_loss           | 0.0693     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 884         |\n",
            "|    ep_rew_mean          | 216         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 775         |\n",
            "|    time_elapsed         | 3823        |\n",
            "|    total_timesteps      | 1587200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010374292 |\n",
            "|    clip_fraction        | 0.0995      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.357       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.124      |\n",
            "|    n_updates            | 7740        |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    std                  | 4.16        |\n",
            "|    value_loss           | 0.051       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 888         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 776         |\n",
            "|    time_elapsed         | 3827        |\n",
            "|    total_timesteps      | 1589248     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007073613 |\n",
            "|    clip_fraction        | 0.0592      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.282       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.109      |\n",
            "|    n_updates            | 7750        |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    std                  | 4.16        |\n",
            "|    value_loss           | 0.0635      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1590000, episode_reward=216.24 +/- 110.36\n",
            "Episode length: 750.00 +/- 203.60\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 750         |\n",
            "|    mean_reward          | 216         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1590000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008268193 |\n",
            "|    clip_fraction        | 0.0648      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.389       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 7760        |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 4.17        |\n",
            "|    value_loss           | 0.055       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 888      |\n",
            "|    ep_rew_mean     | 218      |\n",
            "| time/              |          |\n",
            "|    fps             | 414      |\n",
            "|    iterations      | 777      |\n",
            "|    time_elapsed    | 3836     |\n",
            "|    total_timesteps | 1591296  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 888         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 414         |\n",
            "|    iterations           | 778         |\n",
            "|    time_elapsed         | 3839        |\n",
            "|    total_timesteps      | 1593344     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009144219 |\n",
            "|    clip_fraction        | 0.0891      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.444       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 7770        |\n",
            "|    policy_gradient_loss | -0.0172     |\n",
            "|    std                  | 4.18        |\n",
            "|    value_loss           | 0.0622      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 895          |\n",
            "|    ep_rew_mean          | 220          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 779          |\n",
            "|    time_elapsed         | 3843         |\n",
            "|    total_timesteps      | 1595392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0087240925 |\n",
            "|    clip_fraction        | 0.0753       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | 0.444        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.125       |\n",
            "|    n_updates            | 7780         |\n",
            "|    policy_gradient_loss | -0.0144      |\n",
            "|    std                  | 4.23         |\n",
            "|    value_loss           | 0.0557       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 894          |\n",
            "|    ep_rew_mean          | 222          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 780          |\n",
            "|    time_elapsed         | 3846         |\n",
            "|    total_timesteps      | 1597440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059956666 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | 0.775        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0939      |\n",
            "|    n_updates            | 7790         |\n",
            "|    policy_gradient_loss | -0.0129      |\n",
            "|    std                  | 4.25         |\n",
            "|    value_loss           | 0.201        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 887         |\n",
            "|    ep_rew_mean          | 219         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 781         |\n",
            "|    time_elapsed         | 3850        |\n",
            "|    total_timesteps      | 1599488     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009608597 |\n",
            "|    clip_fraction        | 0.093       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | 0.214       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.122      |\n",
            "|    n_updates            | 7800        |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    std                  | 4.26        |\n",
            "|    value_loss           | 0.0604      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1600000, episode_reward=269.60 +/- 0.98\n",
            "Episode length: 869.60 +/- 8.50\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 870          |\n",
            "|    mean_reward          | 270          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1600000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067685344 |\n",
            "|    clip_fraction        | 0.0459       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.4        |\n",
            "|    explained_variance   | 0.867        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.111       |\n",
            "|    n_updates            | 7810         |\n",
            "|    policy_gradient_loss | -0.014       |\n",
            "|    std                  | 4.25         |\n",
            "|    value_loss           | 0.0821       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 898      |\n",
            "|    ep_rew_mean     | 224      |\n",
            "| time/              |          |\n",
            "|    fps             | 414      |\n",
            "|    iterations      | 782      |\n",
            "|    time_elapsed    | 3859     |\n",
            "|    total_timesteps | 1601536  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 902         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 783         |\n",
            "|    time_elapsed         | 3863        |\n",
            "|    total_timesteps      | 1603584     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009831138 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | 0.376       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 7820        |\n",
            "|    policy_gradient_loss | -0.0185     |\n",
            "|    std                  | 4.24        |\n",
            "|    value_loss           | 0.0596      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 902         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 784         |\n",
            "|    time_elapsed         | 3867        |\n",
            "|    total_timesteps      | 1605632     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008992691 |\n",
            "|    clip_fraction        | 0.0903      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | 0.319       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.1        |\n",
            "|    n_updates            | 7830        |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 4.26        |\n",
            "|    value_loss           | 0.0535      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 902         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 785         |\n",
            "|    time_elapsed         | 3870        |\n",
            "|    total_timesteps      | 1607680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009814747 |\n",
            "|    clip_fraction        | 0.107       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | 0.401       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.117      |\n",
            "|    n_updates            | 7840        |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    std                  | 4.26        |\n",
            "|    value_loss           | 0.0541      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 904         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 786         |\n",
            "|    time_elapsed         | 3873        |\n",
            "|    total_timesteps      | 1609728     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009084217 |\n",
            "|    clip_fraction        | 0.0889      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.4       |\n",
            "|    explained_variance   | 0.499       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 7850        |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    std                  | 4.28        |\n",
            "|    value_loss           | 0.0468      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1610000, episode_reward=250.27 +/- 40.91\n",
            "Episode length: 854.60 +/- 14.65\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 855        |\n",
            "|    mean_reward          | 250        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 1610000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01121324 |\n",
            "|    clip_fraction        | 0.0956     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -11.4      |\n",
            "|    explained_variance   | 0.375      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.11      |\n",
            "|    n_updates            | 7860       |\n",
            "|    policy_gradient_loss | -0.016     |\n",
            "|    std                  | 4.28       |\n",
            "|    value_loss           | 0.0682     |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 903      |\n",
            "|    ep_rew_mean     | 228      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 787      |\n",
            "|    time_elapsed    | 3883     |\n",
            "|    total_timesteps | 1611776  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 903         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 788         |\n",
            "|    time_elapsed         | 3886        |\n",
            "|    total_timesteps      | 1613824     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008041738 |\n",
            "|    clip_fraction        | 0.0572      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.882       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 7870        |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    std                  | 4.31        |\n",
            "|    value_loss           | 0.105       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 903         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 789         |\n",
            "|    time_elapsed         | 3891        |\n",
            "|    total_timesteps      | 1615872     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009677151 |\n",
            "|    clip_fraction        | 0.0923      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.402       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.106      |\n",
            "|    n_updates            | 7880        |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    std                  | 4.33        |\n",
            "|    value_loss           | 0.0525      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 900         |\n",
            "|    ep_rew_mean          | 226         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 790         |\n",
            "|    time_elapsed         | 3894        |\n",
            "|    total_timesteps      | 1617920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008515014 |\n",
            "|    clip_fraction        | 0.0907      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.31        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.117      |\n",
            "|    n_updates            | 7890        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 4.32        |\n",
            "|    value_loss           | 0.0518      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 883         |\n",
            "|    ep_rew_mean          | 219         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 791         |\n",
            "|    time_elapsed         | 3897        |\n",
            "|    total_timesteps      | 1619968     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011376913 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.851       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0787     |\n",
            "|    n_updates            | 7900        |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    std                  | 4.35        |\n",
            "|    value_loss           | 0.15        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1620000, episode_reward=268.71 +/- 1.21\n",
            "Episode length: 871.60 +/- 9.48\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 872         |\n",
            "|    mean_reward          | 269         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1620000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009911295 |\n",
            "|    clip_fraction        | 0.0586      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.875       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.034      |\n",
            "|    n_updates            | 7910        |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    std                  | 4.38        |\n",
            "|    value_loss           | 0.432       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 892      |\n",
            "|    ep_rew_mean     | 222      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 792      |\n",
            "|    time_elapsed    | 3907     |\n",
            "|    total_timesteps | 1622016  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 892         |\n",
            "|    ep_rew_mean          | 222         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 793         |\n",
            "|    time_elapsed         | 3910        |\n",
            "|    total_timesteps      | 1624064     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008973185 |\n",
            "|    clip_fraction        | 0.075       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | -0.311      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 7920        |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    std                  | 4.37        |\n",
            "|    value_loss           | 0.091       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 891         |\n",
            "|    ep_rew_mean          | 222         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 794         |\n",
            "|    time_elapsed         | 3913        |\n",
            "|    total_timesteps      | 1626112     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010204615 |\n",
            "|    clip_fraction        | 0.0863      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.269       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.107      |\n",
            "|    n_updates            | 7930        |\n",
            "|    policy_gradient_loss | -0.015      |\n",
            "|    std                  | 4.38        |\n",
            "|    value_loss           | 0.0528      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 891         |\n",
            "|    ep_rew_mean          | 222         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 795         |\n",
            "|    time_elapsed         | 3918        |\n",
            "|    total_timesteps      | 1628160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007597924 |\n",
            "|    clip_fraction        | 0.0593      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.5       |\n",
            "|    explained_variance   | 0.309       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.126      |\n",
            "|    n_updates            | 7940        |\n",
            "|    policy_gradient_loss | -0.0153     |\n",
            "|    std                  | 4.4         |\n",
            "|    value_loss           | 0.0538      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1630000, episode_reward=269.68 +/- 0.87\n",
            "Episode length: 866.20 +/- 7.52\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 866         |\n",
            "|    mean_reward          | 270         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1630000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011350071 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.465       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 7950        |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    std                  | 4.43        |\n",
            "|    value_loss           | 0.0487      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 899      |\n",
            "|    ep_rew_mean     | 225      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 796      |\n",
            "|    time_elapsed    | 3926     |\n",
            "|    total_timesteps | 1630208  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 901         |\n",
            "|    ep_rew_mean          | 225         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 797         |\n",
            "|    time_elapsed         | 3931        |\n",
            "|    total_timesteps      | 1632256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010736594 |\n",
            "|    clip_fraction        | 0.125       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.538       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.123      |\n",
            "|    n_updates            | 7960        |\n",
            "|    policy_gradient_loss | -0.0208     |\n",
            "|    std                  | 4.45        |\n",
            "|    value_loss           | 0.0637      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 902         |\n",
            "|    ep_rew_mean          | 225         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 798         |\n",
            "|    time_elapsed         | 3934        |\n",
            "|    total_timesteps      | 1634304     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009100703 |\n",
            "|    clip_fraction        | 0.0901      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.559       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.112      |\n",
            "|    n_updates            | 7970        |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    std                  | 4.48        |\n",
            "|    value_loss           | 0.052       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 901         |\n",
            "|    ep_rew_mean          | 225         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 799         |\n",
            "|    time_elapsed         | 3938        |\n",
            "|    total_timesteps      | 1636352     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008570685 |\n",
            "|    clip_fraction        | 0.0774      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.239       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.121      |\n",
            "|    n_updates            | 7980        |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    std                  | 4.48        |\n",
            "|    value_loss           | 0.0791      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 902         |\n",
            "|    ep_rew_mean          | 225         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 800         |\n",
            "|    time_elapsed         | 3941        |\n",
            "|    total_timesteps      | 1638400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010786919 |\n",
            "|    clip_fraction        | 0.0874      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.138       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.117      |\n",
            "|    n_updates            | 7990        |\n",
            "|    policy_gradient_loss | -0.017      |\n",
            "|    std                  | 4.48        |\n",
            "|    value_loss           | 0.0641      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1640000, episode_reward=269.40 +/- 0.37\n",
            "Episode length: 868.00 +/- 6.42\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 868         |\n",
            "|    mean_reward          | 269         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1640000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009649992 |\n",
            "|    clip_fraction        | 0.083       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.339       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.122      |\n",
            "|    n_updates            | 8000        |\n",
            "|    policy_gradient_loss | -0.014      |\n",
            "|    std                  | 4.47        |\n",
            "|    value_loss           | 0.0489      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 902      |\n",
            "|    ep_rew_mean     | 225      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 801      |\n",
            "|    time_elapsed    | 3951     |\n",
            "|    total_timesteps | 1640448  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 905         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 802         |\n",
            "|    time_elapsed         | 3955        |\n",
            "|    total_timesteps      | 1642496     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009444833 |\n",
            "|    clip_fraction        | 0.0866      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.552       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.118      |\n",
            "|    n_updates            | 8010        |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    std                  | 4.49        |\n",
            "|    value_loss           | 0.0534      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 906         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 803         |\n",
            "|    time_elapsed         | 3959        |\n",
            "|    total_timesteps      | 1644544     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008030118 |\n",
            "|    clip_fraction        | 0.0715      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.298       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.136      |\n",
            "|    n_updates            | 8020        |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    std                  | 4.5         |\n",
            "|    value_loss           | 0.0517      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 906         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 804         |\n",
            "|    time_elapsed         | 3962        |\n",
            "|    total_timesteps      | 1646592     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009394356 |\n",
            "|    clip_fraction        | 0.0908      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.6       |\n",
            "|    explained_variance   | 0.411       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0989     |\n",
            "|    n_updates            | 8030        |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    std                  | 4.53        |\n",
            "|    value_loss           | 0.0538      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 908         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 805         |\n",
            "|    time_elapsed         | 3965        |\n",
            "|    total_timesteps      | 1648640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008300606 |\n",
            "|    clip_fraction        | 0.0617      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | 0.441       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.107      |\n",
            "|    n_updates            | 8040        |\n",
            "|    policy_gradient_loss | -0.0125     |\n",
            "|    std                  | 4.58        |\n",
            "|    value_loss           | 0.0515      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1650000, episode_reward=268.89 +/- 0.88\n",
            "Episode length: 872.40 +/- 9.81\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 872         |\n",
            "|    mean_reward          | 269         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1650000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009154591 |\n",
            "|    clip_fraction        | 0.0867      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | 0.619       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.133      |\n",
            "|    n_updates            | 8050        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 4.6         |\n",
            "|    value_loss           | 0.046       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 917      |\n",
            "|    ep_rew_mean     | 233      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 806      |\n",
            "|    time_elapsed    | 3975     |\n",
            "|    total_timesteps | 1650688  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 917          |\n",
            "|    ep_rew_mean          | 233          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 807          |\n",
            "|    time_elapsed         | 3979         |\n",
            "|    total_timesteps      | 1652736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0100636035 |\n",
            "|    clip_fraction        | 0.102        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.7        |\n",
            "|    explained_variance   | 0.487        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.105       |\n",
            "|    n_updates            | 8060         |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    std                  | 4.62         |\n",
            "|    value_loss           | 0.061        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 918         |\n",
            "|    ep_rew_mean          | 233         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 808         |\n",
            "|    time_elapsed         | 3982        |\n",
            "|    total_timesteps      | 1654784     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010201987 |\n",
            "|    clip_fraction        | 0.093       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.7       |\n",
            "|    explained_variance   | 0.311       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 8070        |\n",
            "|    policy_gradient_loss | -0.0177     |\n",
            "|    std                  | 4.64        |\n",
            "|    value_loss           | 0.0533      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 918         |\n",
            "|    ep_rew_mean          | 233         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 809         |\n",
            "|    time_elapsed         | 3986        |\n",
            "|    total_timesteps      | 1656832     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008830858 |\n",
            "|    clip_fraction        | 0.0764      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.265       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.116      |\n",
            "|    n_updates            | 8080        |\n",
            "|    policy_gradient_loss | -0.015      |\n",
            "|    std                  | 4.64        |\n",
            "|    value_loss           | 0.0561      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 918         |\n",
            "|    ep_rew_mean          | 233         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 810         |\n",
            "|    time_elapsed         | 3990        |\n",
            "|    total_timesteps      | 1658880     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006186674 |\n",
            "|    clip_fraction        | 0.0459      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.391       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.101      |\n",
            "|    n_updates            | 8090        |\n",
            "|    policy_gradient_loss | -0.0133     |\n",
            "|    std                  | 4.66        |\n",
            "|    value_loss           | 0.0497      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1660000, episode_reward=231.76 +/- 74.49\n",
            "Episode length: 819.40 +/- 99.05\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 819         |\n",
            "|    mean_reward          | 232         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1660000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007327444 |\n",
            "|    clip_fraction        | 0.0653      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.455       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.119      |\n",
            "|    n_updates            | 8100        |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    std                  | 4.69        |\n",
            "|    value_loss           | 0.0472      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 916      |\n",
            "|    ep_rew_mean     | 232      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 811      |\n",
            "|    time_elapsed    | 3999     |\n",
            "|    total_timesteps | 1660928  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 916         |\n",
            "|    ep_rew_mean          | 232         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 812         |\n",
            "|    time_elapsed         | 4003        |\n",
            "|    total_timesteps      | 1662976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006777974 |\n",
            "|    clip_fraction        | 0.0454      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.805       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0708     |\n",
            "|    n_updates            | 8110        |\n",
            "|    policy_gradient_loss | -0.0163     |\n",
            "|    std                  | 4.72        |\n",
            "|    value_loss           | 0.168       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 900        |\n",
            "|    ep_rew_mean          | 226        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 813        |\n",
            "|    time_elapsed         | 4006       |\n",
            "|    total_timesteps      | 1665024    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00934615 |\n",
            "|    clip_fraction        | 0.0772     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -11.8      |\n",
            "|    explained_variance   | 0.354      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.106     |\n",
            "|    n_updates            | 8120       |\n",
            "|    policy_gradient_loss | -0.0175    |\n",
            "|    std                  | 4.72       |\n",
            "|    value_loss           | 0.0651     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 899         |\n",
            "|    ep_rew_mean          | 225         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 814         |\n",
            "|    time_elapsed         | 4010        |\n",
            "|    total_timesteps      | 1667072     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007860648 |\n",
            "|    clip_fraction        | 0.0614      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.841       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.107      |\n",
            "|    n_updates            | 8130        |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    std                  | 4.72        |\n",
            "|    value_loss           | 0.165       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 909         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 815         |\n",
            "|    time_elapsed         | 4014        |\n",
            "|    total_timesteps      | 1669120     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008055342 |\n",
            "|    clip_fraction        | 0.0572      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.793       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0635     |\n",
            "|    n_updates            | 8140        |\n",
            "|    policy_gradient_loss | -0.0168     |\n",
            "|    std                  | 4.73        |\n",
            "|    value_loss           | 0.215       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1670000, episode_reward=180.84 +/- 110.59\n",
            "Episode length: 724.20 +/- 185.66\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 724        |\n",
            "|    mean_reward          | 181        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 1670000    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00823424 |\n",
            "|    clip_fraction        | 0.0754     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -11.8      |\n",
            "|    explained_variance   | 0.337      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.128     |\n",
            "|    n_updates            | 8150       |\n",
            "|    policy_gradient_loss | -0.015     |\n",
            "|    std                  | 4.75       |\n",
            "|    value_loss           | 0.0447     |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 891      |\n",
            "|    ep_rew_mean     | 220      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 816      |\n",
            "|    time_elapsed    | 4022     |\n",
            "|    total_timesteps | 1671168  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 892         |\n",
            "|    ep_rew_mean          | 220         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 817         |\n",
            "|    time_elapsed         | 4026        |\n",
            "|    total_timesteps      | 1673216     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007008846 |\n",
            "|    clip_fraction        | 0.0514      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.885       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0687     |\n",
            "|    n_updates            | 8160        |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    std                  | 4.78        |\n",
            "|    value_loss           | 0.365       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 886          |\n",
            "|    ep_rew_mean          | 218          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 818          |\n",
            "|    time_elapsed         | 4029         |\n",
            "|    total_timesteps      | 1675264      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070293765 |\n",
            "|    clip_fraction        | 0.0435       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.8        |\n",
            "|    explained_variance   | -0.653       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.106       |\n",
            "|    n_updates            | 8170         |\n",
            "|    policy_gradient_loss | -0.0143      |\n",
            "|    std                  | 4.73         |\n",
            "|    value_loss           | 0.0928       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 885         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 819         |\n",
            "|    time_elapsed         | 4032        |\n",
            "|    total_timesteps      | 1677312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009190891 |\n",
            "|    clip_fraction        | 0.0701      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.905       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.118      |\n",
            "|    n_updates            | 8180        |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    std                  | 4.72        |\n",
            "|    value_loss           | 0.111       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 885         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 820         |\n",
            "|    time_elapsed         | 4036        |\n",
            "|    total_timesteps      | 1679360     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009490652 |\n",
            "|    clip_fraction        | 0.0776      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.174       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.121      |\n",
            "|    n_updates            | 8190        |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    std                  | 4.73        |\n",
            "|    value_loss           | 0.0817      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1680000, episode_reward=267.74 +/- 2.28\n",
            "Episode length: 877.60 +/- 21.38\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 878         |\n",
            "|    mean_reward          | 268         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1680000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009518745 |\n",
            "|    clip_fraction        | 0.0975      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.29        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.132      |\n",
            "|    n_updates            | 8200        |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    std                  | 4.74        |\n",
            "|    value_loss           | 0.0482      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 884      |\n",
            "|    ep_rew_mean     | 218      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 821      |\n",
            "|    time_elapsed    | 4046     |\n",
            "|    total_timesteps | 1681408  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 884         |\n",
            "|    ep_rew_mean          | 217         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 822         |\n",
            "|    time_elapsed         | 4049        |\n",
            "|    total_timesteps      | 1683456     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012679407 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.565       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 8210        |\n",
            "|    policy_gradient_loss | -0.0179     |\n",
            "|    std                  | 4.76        |\n",
            "|    value_loss           | 0.0496      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 885         |\n",
            "|    ep_rew_mean          | 217         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 823         |\n",
            "|    time_elapsed         | 4053        |\n",
            "|    total_timesteps      | 1685504     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009053718 |\n",
            "|    clip_fraction        | 0.0626      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.857       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0728     |\n",
            "|    n_updates            | 8220        |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 4.77        |\n",
            "|    value_loss           | 0.136       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 887         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 824         |\n",
            "|    time_elapsed         | 4057        |\n",
            "|    total_timesteps      | 1687552     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010483068 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.475       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.117      |\n",
            "|    n_updates            | 8230        |\n",
            "|    policy_gradient_loss | -0.0168     |\n",
            "|    std                  | 4.76        |\n",
            "|    value_loss           | 0.0548      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 888         |\n",
            "|    ep_rew_mean          | 218         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 825         |\n",
            "|    time_elapsed         | 4060        |\n",
            "|    total_timesteps      | 1689600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009632668 |\n",
            "|    clip_fraction        | 0.094       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.408       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.107      |\n",
            "|    n_updates            | 8240        |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    std                  | 4.78        |\n",
            "|    value_loss           | 0.0503      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1690000, episode_reward=246.96 +/- 48.86\n",
            "Episode length: 851.00 +/- 7.51\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 851         |\n",
            "|    mean_reward          | 247         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1690000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007025204 |\n",
            "|    clip_fraction        | 0.0497      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.421       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.131      |\n",
            "|    n_updates            | 8250        |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    std                  | 4.8         |\n",
            "|    value_loss           | 0.0604      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 887      |\n",
            "|    ep_rew_mean     | 218      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 826      |\n",
            "|    time_elapsed    | 4070     |\n",
            "|    total_timesteps | 1691648  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 895         |\n",
            "|    ep_rew_mean          | 222         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 827         |\n",
            "|    time_elapsed         | 4073        |\n",
            "|    total_timesteps      | 1693696     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014009558 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.402       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0963     |\n",
            "|    n_updates            | 8260        |\n",
            "|    policy_gradient_loss | -0.0163     |\n",
            "|    std                  | 4.82        |\n",
            "|    value_loss           | 0.0676      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 889         |\n",
            "|    ep_rew_mean          | 219         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 828         |\n",
            "|    time_elapsed         | 4077        |\n",
            "|    total_timesteps      | 1695744     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009782519 |\n",
            "|    clip_fraction        | 0.0797      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.543       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.128      |\n",
            "|    n_updates            | 8270        |\n",
            "|    policy_gradient_loss | -0.0175     |\n",
            "|    std                  | 4.79        |\n",
            "|    value_loss           | 0.0504      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 889          |\n",
            "|    ep_rew_mean          | 219          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 829          |\n",
            "|    time_elapsed         | 4081         |\n",
            "|    total_timesteps      | 1697792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074210064 |\n",
            "|    clip_fraction        | 0.0538       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.86         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.13        |\n",
            "|    n_updates            | 8280         |\n",
            "|    policy_gradient_loss | -0.015       |\n",
            "|    std                  | 4.78         |\n",
            "|    value_loss           | 0.139        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 891         |\n",
            "|    ep_rew_mean          | 219         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 830         |\n",
            "|    time_elapsed         | 4084        |\n",
            "|    total_timesteps      | 1699840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008816658 |\n",
            "|    clip_fraction        | 0.0753      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.487       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 8290        |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    std                  | 4.75        |\n",
            "|    value_loss           | 0.0601      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1700000, episode_reward=270.93 +/- 0.74\n",
            "Episode length: 853.60 +/- 3.20\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 854         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1700000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009406959 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.419       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.116      |\n",
            "|    n_updates            | 8300        |\n",
            "|    policy_gradient_loss | -0.0179     |\n",
            "|    std                  | 4.74        |\n",
            "|    value_loss           | 0.0558      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 890      |\n",
            "|    ep_rew_mean     | 219      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 831      |\n",
            "|    time_elapsed    | 4094     |\n",
            "|    total_timesteps | 1701888  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 890         |\n",
            "|    ep_rew_mean          | 219         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 832         |\n",
            "|    time_elapsed         | 4097        |\n",
            "|    total_timesteps      | 1703936     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008057129 |\n",
            "|    clip_fraction        | 0.0944      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.546       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.114      |\n",
            "|    n_updates            | 8310        |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    std                  | 4.76        |\n",
            "|    value_loss           | 0.0776      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 879         |\n",
            "|    ep_rew_mean          | 215         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 833         |\n",
            "|    time_elapsed         | 4100        |\n",
            "|    total_timesteps      | 1705984     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009672853 |\n",
            "|    clip_fraction        | 0.0733      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.158       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 8320        |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    std                  | 4.76        |\n",
            "|    value_loss           | 0.0679      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 879         |\n",
            "|    ep_rew_mean          | 215         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 834         |\n",
            "|    time_elapsed         | 4105        |\n",
            "|    total_timesteps      | 1708032     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010010647 |\n",
            "|    clip_fraction        | 0.0908      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.854       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0302     |\n",
            "|    n_updates            | 8330        |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    std                  | 4.77        |\n",
            "|    value_loss           | 0.323       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1710000, episode_reward=-33.99 +/- 151.03\n",
            "Episode length: 291.20 +/- 302.49\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 291         |\n",
            "|    mean_reward          | -34         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1710000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008876899 |\n",
            "|    clip_fraction        | 0.0867      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.00262     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.115      |\n",
            "|    n_updates            | 8340        |\n",
            "|    policy_gradient_loss | -0.0168     |\n",
            "|    std                  | 4.73        |\n",
            "|    value_loss           | 0.0639      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 882      |\n",
            "|    ep_rew_mean     | 217      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 835      |\n",
            "|    time_elapsed    | 4110     |\n",
            "|    total_timesteps | 1710080  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 890         |\n",
            "|    ep_rew_mean          | 221         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 836         |\n",
            "|    time_elapsed         | 4113        |\n",
            "|    total_timesteps      | 1712128     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010277914 |\n",
            "|    clip_fraction        | 0.0844      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.441       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.108      |\n",
            "|    n_updates            | 8350        |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    std                  | 4.71        |\n",
            "|    value_loss           | 0.0554      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 899         |\n",
            "|    ep_rew_mean          | 226         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 837         |\n",
            "|    time_elapsed         | 4118        |\n",
            "|    total_timesteps      | 1714176     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008215521 |\n",
            "|    clip_fraction        | 0.0661      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.346       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.118      |\n",
            "|    n_updates            | 8360        |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    std                  | 4.72        |\n",
            "|    value_loss           | 0.0515      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 895         |\n",
            "|    ep_rew_mean          | 224         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 838         |\n",
            "|    time_elapsed         | 4121        |\n",
            "|    total_timesteps      | 1716224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009776572 |\n",
            "|    clip_fraction        | 0.0888      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.345       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.115      |\n",
            "|    n_updates            | 8370        |\n",
            "|    policy_gradient_loss | -0.0141     |\n",
            "|    std                  | 4.74        |\n",
            "|    value_loss           | 0.0514      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 895         |\n",
            "|    ep_rew_mean          | 224         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 839         |\n",
            "|    time_elapsed         | 4125        |\n",
            "|    total_timesteps      | 1718272     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008629141 |\n",
            "|    clip_fraction        | 0.0654      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.8       |\n",
            "|    explained_variance   | 0.92        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.118      |\n",
            "|    n_updates            | 8380        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 4.76        |\n",
            "|    value_loss           | 0.118       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1720000, episode_reward=212.88 +/- 117.27\n",
            "Episode length: 741.20 +/- 221.44\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 741         |\n",
            "|    mean_reward          | 213         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1720000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008520225 |\n",
            "|    clip_fraction        | 0.0828      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | -0.0451     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0906     |\n",
            "|    n_updates            | 8390        |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    std                  | 4.79        |\n",
            "|    value_loss           | 0.0842      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 885      |\n",
            "|    ep_rew_mean     | 220      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 840      |\n",
            "|    time_elapsed    | 4134     |\n",
            "|    total_timesteps | 1720320  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 884         |\n",
            "|    ep_rew_mean          | 220         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 841         |\n",
            "|    time_elapsed         | 4137        |\n",
            "|    total_timesteps      | 1722368     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007529975 |\n",
            "|    clip_fraction        | 0.0502      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.79        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.112      |\n",
            "|    n_updates            | 8400        |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    std                  | 4.81        |\n",
            "|    value_loss           | 0.141       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 865         |\n",
            "|    ep_rew_mean          | 213         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 842         |\n",
            "|    time_elapsed         | 4140        |\n",
            "|    total_timesteps      | 1724416     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010481574 |\n",
            "|    clip_fraction        | 0.0993      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.398       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.128      |\n",
            "|    n_updates            | 8410        |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    std                  | 4.81        |\n",
            "|    value_loss           | 0.0614      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 855        |\n",
            "|    ep_rew_mean          | 210        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 416        |\n",
            "|    iterations           | 843        |\n",
            "|    time_elapsed         | 4145       |\n",
            "|    total_timesteps      | 1726464    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00615052 |\n",
            "|    clip_fraction        | 0.0364     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -11.9      |\n",
            "|    explained_variance   | 0.898      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0995    |\n",
            "|    n_updates            | 8420       |\n",
            "|    policy_gradient_loss | -0.0126    |\n",
            "|    std                  | 4.8        |\n",
            "|    value_loss           | 0.158      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 831         |\n",
            "|    ep_rew_mean          | 200         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 844         |\n",
            "|    time_elapsed         | 4148        |\n",
            "|    total_timesteps      | 1728512     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007261055 |\n",
            "|    clip_fraction        | 0.0544      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.921       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0739     |\n",
            "|    n_updates            | 8430        |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    std                  | 4.84        |\n",
            "|    value_loss           | 0.133       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1730000, episode_reward=269.59 +/- 1.11\n",
            "Episode length: 865.20 +/- 9.17\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 865          |\n",
            "|    mean_reward          | 270          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1730000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073460494 |\n",
            "|    clip_fraction        | 0.0438       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -11.9        |\n",
            "|    explained_variance   | 0.887        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.000441     |\n",
            "|    n_updates            | 8440         |\n",
            "|    policy_gradient_loss | -0.0168      |\n",
            "|    std                  | 4.85         |\n",
            "|    value_loss           | 0.386        |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 831      |\n",
            "|    ep_rew_mean     | 200      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 845      |\n",
            "|    time_elapsed    | 4157     |\n",
            "|    total_timesteps | 1730560  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 830         |\n",
            "|    ep_rew_mean          | 200         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 846         |\n",
            "|    time_elapsed         | 4161        |\n",
            "|    total_timesteps      | 1732608     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007527367 |\n",
            "|    clip_fraction        | 0.0558      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.9       |\n",
            "|    explained_variance   | 0.294       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 8450        |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    std                  | 4.86        |\n",
            "|    value_loss           | 0.0516      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 830         |\n",
            "|    ep_rew_mean          | 200         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 847         |\n",
            "|    time_elapsed         | 4164        |\n",
            "|    total_timesteps      | 1734656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007615827 |\n",
            "|    clip_fraction        | 0.0657      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | 0.358       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 8460        |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    std                  | 4.89        |\n",
            "|    value_loss           | 0.0566      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 830          |\n",
            "|    ep_rew_mean          | 200          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 848          |\n",
            "|    time_elapsed         | 4168         |\n",
            "|    total_timesteps      | 1736704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0097137075 |\n",
            "|    clip_fraction        | 0.0839       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0969      |\n",
            "|    n_updates            | 8470         |\n",
            "|    policy_gradient_loss | -0.0146      |\n",
            "|    std                  | 4.9          |\n",
            "|    value_loss           | 0.054        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 830          |\n",
            "|    ep_rew_mean          | 200          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 849          |\n",
            "|    time_elapsed         | 4172         |\n",
            "|    total_timesteps      | 1738752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069125425 |\n",
            "|    clip_fraction        | 0.0494       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12          |\n",
            "|    explained_variance   | 0.496        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.136       |\n",
            "|    n_updates            | 8480         |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    std                  | 4.93         |\n",
            "|    value_loss           | 0.0553       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1740000, episode_reward=208.26 +/- 127.47\n",
            "Episode length: 717.20 +/- 246.23\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 717         |\n",
            "|    mean_reward          | 208         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1740000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008220029 |\n",
            "|    clip_fraction        | 0.0698      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | 0.443       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0888     |\n",
            "|    n_updates            | 8490        |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    std                  | 4.95        |\n",
            "|    value_loss           | 0.0793      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 826      |\n",
            "|    ep_rew_mean     | 198      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 850      |\n",
            "|    time_elapsed    | 4180     |\n",
            "|    total_timesteps | 1740800  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 824         |\n",
            "|    ep_rew_mean          | 198         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 851         |\n",
            "|    time_elapsed         | 4184        |\n",
            "|    total_timesteps      | 1742848     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010070178 |\n",
            "|    clip_fraction        | 0.0976      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12         |\n",
            "|    explained_variance   | 0.863       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.108      |\n",
            "|    n_updates            | 8500        |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    std                  | 4.99        |\n",
            "|    value_loss           | 0.154       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 823          |\n",
            "|    ep_rew_mean          | 198          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 852          |\n",
            "|    time_elapsed         | 4188         |\n",
            "|    total_timesteps      | 1744896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078007695 |\n",
            "|    clip_fraction        | 0.067        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | -0.253       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.121       |\n",
            "|    n_updates            | 8510         |\n",
            "|    policy_gradient_loss | -0.0159      |\n",
            "|    std                  | 4.99         |\n",
            "|    value_loss           | 0.128        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 820          |\n",
            "|    ep_rew_mean          | 197          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 853          |\n",
            "|    time_elapsed         | 4191         |\n",
            "|    total_timesteps      | 1746944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0104034655 |\n",
            "|    clip_fraction        | 0.0968       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.334        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.129       |\n",
            "|    n_updates            | 8520         |\n",
            "|    policy_gradient_loss | -0.0172      |\n",
            "|    std                  | 5.02         |\n",
            "|    value_loss           | 0.0573       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 828         |\n",
            "|    ep_rew_mean          | 200         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 854         |\n",
            "|    time_elapsed         | 4194        |\n",
            "|    total_timesteps      | 1748992     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009036399 |\n",
            "|    clip_fraction        | 0.0662      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.907       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.115      |\n",
            "|    n_updates            | 8530        |\n",
            "|    policy_gradient_loss | -0.0156     |\n",
            "|    std                  | 5.07        |\n",
            "|    value_loss           | 0.0725      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1750000, episode_reward=272.33 +/- 0.91\n",
            "Episode length: 837.60 +/- 5.92\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 838         |\n",
            "|    mean_reward          | 272         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1750000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009006696 |\n",
            "|    clip_fraction        | 0.0726      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.391       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 8540        |\n",
            "|    policy_gradient_loss | -0.0167     |\n",
            "|    std                  | 5.07        |\n",
            "|    value_loss           | 0.0542      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 814      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 855      |\n",
            "|    time_elapsed    | 4203     |\n",
            "|    total_timesteps | 1751040  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 814          |\n",
            "|    ep_rew_mean          | 194          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 856          |\n",
            "|    time_elapsed         | 4207         |\n",
            "|    total_timesteps      | 1753088      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066317087 |\n",
            "|    clip_fraction        | 0.0304       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.848        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00791     |\n",
            "|    n_updates            | 8550         |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    std                  | 5.07         |\n",
            "|    value_loss           | 0.493        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 813          |\n",
            "|    ep_rew_mean          | 194          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 857          |\n",
            "|    time_elapsed         | 4211         |\n",
            "|    total_timesteps      | 1755136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063835056 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.873        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.047       |\n",
            "|    n_updates            | 8560         |\n",
            "|    policy_gradient_loss | -0.0158      |\n",
            "|    std                  | 5.06         |\n",
            "|    value_loss           | 0.342        |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 814        |\n",
            "|    ep_rew_mean          | 196        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 416        |\n",
            "|    iterations           | 858        |\n",
            "|    time_elapsed         | 4214       |\n",
            "|    total_timesteps      | 1757184    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00956845 |\n",
            "|    clip_fraction        | 0.0874     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -12.1      |\n",
            "|    explained_variance   | 0.0295     |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.128     |\n",
            "|    n_updates            | 8570       |\n",
            "|    policy_gradient_loss | -0.0166    |\n",
            "|    std                  | 5.04       |\n",
            "|    value_loss           | 0.0545     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 820         |\n",
            "|    ep_rew_mean          | 199         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 859         |\n",
            "|    time_elapsed         | 4218        |\n",
            "|    total_timesteps      | 1759232     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008325315 |\n",
            "|    clip_fraction        | 0.0622      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.353       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.127      |\n",
            "|    n_updates            | 8580        |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    std                  | 5.02        |\n",
            "|    value_loss           | 0.0516      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1760000, episode_reward=271.50 +/- 0.98\n",
            "Episode length: 847.20 +/- 9.24\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 847         |\n",
            "|    mean_reward          | 272         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1760000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006269372 |\n",
            "|    clip_fraction        | 0.0599      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.892       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.089      |\n",
            "|    n_updates            | 8590        |\n",
            "|    policy_gradient_loss | -0.014      |\n",
            "|    std                  | 5.02        |\n",
            "|    value_loss           | 0.128       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 819      |\n",
            "|    ep_rew_mean     | 199      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 860      |\n",
            "|    time_elapsed    | 4227     |\n",
            "|    total_timesteps | 1761280  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 827         |\n",
            "|    ep_rew_mean          | 203         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 861         |\n",
            "|    time_elapsed         | 4231        |\n",
            "|    total_timesteps      | 1763328     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009816023 |\n",
            "|    clip_fraction        | 0.0776      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.527       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.13       |\n",
            "|    n_updates            | 8600        |\n",
            "|    policy_gradient_loss | -0.017      |\n",
            "|    std                  | 5.06        |\n",
            "|    value_loss           | 0.0596      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 827         |\n",
            "|    ep_rew_mean          | 203         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 862         |\n",
            "|    time_elapsed         | 4234        |\n",
            "|    total_timesteps      | 1765376     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009074114 |\n",
            "|    clip_fraction        | 0.0845      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.4         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 8610        |\n",
            "|    policy_gradient_loss | -0.0133     |\n",
            "|    std                  | 5.09        |\n",
            "|    value_loss           | 0.0551      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 827          |\n",
            "|    ep_rew_mean          | 203          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 863          |\n",
            "|    time_elapsed         | 4238         |\n",
            "|    total_timesteps      | 1767424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071890987 |\n",
            "|    clip_fraction        | 0.0667       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.1        |\n",
            "|    explained_variance   | 0.539        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.115       |\n",
            "|    n_updates            | 8620         |\n",
            "|    policy_gradient_loss | -0.0158      |\n",
            "|    std                  | 5.1          |\n",
            "|    value_loss           | 0.0577       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 827         |\n",
            "|    ep_rew_mean          | 203         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 864         |\n",
            "|    time_elapsed         | 4242        |\n",
            "|    total_timesteps      | 1769472     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008461146 |\n",
            "|    clip_fraction        | 0.0898      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.1       |\n",
            "|    explained_variance   | 0.567       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.105      |\n",
            "|    n_updates            | 8630        |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    std                  | 5.12        |\n",
            "|    value_loss           | 0.0554      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1770000, episode_reward=246.64 +/- 47.69\n",
            "Episode length: 844.40 +/- 17.45\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 844          |\n",
            "|    mean_reward          | 247          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1770000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072307894 |\n",
            "|    clip_fraction        | 0.0431       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.2        |\n",
            "|    explained_variance   | 0.843        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.11        |\n",
            "|    n_updates            | 8640         |\n",
            "|    policy_gradient_loss | -0.0138      |\n",
            "|    std                  | 5.14         |\n",
            "|    value_loss           | 0.134        |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 818      |\n",
            "|    ep_rew_mean     | 200      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 865      |\n",
            "|    time_elapsed    | 4251     |\n",
            "|    total_timesteps | 1771520  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 811          |\n",
            "|    ep_rew_mean          | 197          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 866          |\n",
            "|    time_elapsed         | 4254         |\n",
            "|    total_timesteps      | 1773568      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0085778395 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.2        |\n",
            "|    explained_variance   | 0.847        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0955      |\n",
            "|    n_updates            | 8650         |\n",
            "|    policy_gradient_loss | -0.0141      |\n",
            "|    std                  | 5.16         |\n",
            "|    value_loss           | 0.19         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 811         |\n",
            "|    ep_rew_mean          | 197         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 867         |\n",
            "|    time_elapsed         | 4258        |\n",
            "|    total_timesteps      | 1775616     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009342655 |\n",
            "|    clip_fraction        | 0.0915      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | 0.928       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 8660        |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    std                  | 5.19        |\n",
            "|    value_loss           | 0.108       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 810         |\n",
            "|    ep_rew_mean          | 197         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 868         |\n",
            "|    time_elapsed         | 4261        |\n",
            "|    total_timesteps      | 1777664     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009414558 |\n",
            "|    clip_fraction        | 0.0664      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | -0.104      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.115      |\n",
            "|    n_updates            | 8670        |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    std                  | 5.19        |\n",
            "|    value_loss           | 0.0985      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 810          |\n",
            "|    ep_rew_mean          | 197          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 869          |\n",
            "|    time_elapsed         | 4265         |\n",
            "|    total_timesteps      | 1779712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074417433 |\n",
            "|    clip_fraction        | 0.0631       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.2        |\n",
            "|    explained_variance   | 0.495        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.127       |\n",
            "|    n_updates            | 8680         |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    std                  | 5.18         |\n",
            "|    value_loss           | 0.0498       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1780000, episode_reward=239.23 +/- 63.17\n",
            "Episode length: 822.80 +/- 59.46\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 823         |\n",
            "|    mean_reward          | 239         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1780000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008491939 |\n",
            "|    clip_fraction        | 0.092       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | 0.446       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.13       |\n",
            "|    n_updates            | 8690        |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    std                  | 5.19        |\n",
            "|    value_loss           | 0.0511      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 811      |\n",
            "|    ep_rew_mean     | 197      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 870      |\n",
            "|    time_elapsed    | 4274     |\n",
            "|    total_timesteps | 1781760  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 817         |\n",
            "|    ep_rew_mean          | 200         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 871         |\n",
            "|    time_elapsed         | 4278        |\n",
            "|    total_timesteps      | 1783808     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008941528 |\n",
            "|    clip_fraction        | 0.0827      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | 0.424       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.117      |\n",
            "|    n_updates            | 8700        |\n",
            "|    policy_gradient_loss | -0.0172     |\n",
            "|    std                  | 5.18        |\n",
            "|    value_loss           | 0.0745      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 814         |\n",
            "|    ep_rew_mean          | 200         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 872         |\n",
            "|    time_elapsed         | 4281        |\n",
            "|    total_timesteps      | 1785856     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008758428 |\n",
            "|    clip_fraction        | 0.0702      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | 0.496       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 8710        |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    std                  | 5.19        |\n",
            "|    value_loss           | 0.0583      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 805          |\n",
            "|    ep_rew_mean          | 196          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 873          |\n",
            "|    time_elapsed         | 4284         |\n",
            "|    total_timesteps      | 1787904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073912106 |\n",
            "|    clip_fraction        | 0.0702       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.2        |\n",
            "|    explained_variance   | 0.461        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.119       |\n",
            "|    n_updates            | 8720         |\n",
            "|    policy_gradient_loss | -0.0136      |\n",
            "|    std                  | 5.24         |\n",
            "|    value_loss           | 0.0796       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 804          |\n",
            "|    ep_rew_mean          | 196          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 874          |\n",
            "|    time_elapsed         | 4288         |\n",
            "|    total_timesteps      | 1789952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058226045 |\n",
            "|    clip_fraction        | 0.0448       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.3        |\n",
            "|    explained_variance   | 0.877        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.131       |\n",
            "|    n_updates            | 8730         |\n",
            "|    policy_gradient_loss | -0.0115      |\n",
            "|    std                  | 5.24         |\n",
            "|    value_loss           | 0.0858       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1790000, episode_reward=242.57 +/- 59.02\n",
            "Episode length: 817.60 +/- 36.21\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 818         |\n",
            "|    mean_reward          | 243         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1790000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010914882 |\n",
            "|    clip_fraction        | 0.0842      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | 0.394       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.112      |\n",
            "|    n_updates            | 8740        |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    std                  | 5.21        |\n",
            "|    value_loss           | 0.0603      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 807      |\n",
            "|    ep_rew_mean     | 199      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 875      |\n",
            "|    time_elapsed    | 4297     |\n",
            "|    total_timesteps | 1792000  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 804         |\n",
            "|    ep_rew_mean          | 197         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 876         |\n",
            "|    time_elapsed         | 4301        |\n",
            "|    total_timesteps      | 1794048     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007849341 |\n",
            "|    clip_fraction        | 0.0485      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.2       |\n",
            "|    explained_variance   | 0.846       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0014      |\n",
            "|    n_updates            | 8750        |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    std                  | 5.19        |\n",
            "|    value_loss           | 0.188       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 802          |\n",
            "|    ep_rew_mean          | 195          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 877          |\n",
            "|    time_elapsed         | 4305         |\n",
            "|    total_timesteps      | 1796096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058103455 |\n",
            "|    clip_fraction        | 0.0549       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.2        |\n",
            "|    explained_variance   | 0.861        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0533      |\n",
            "|    n_updates            | 8760         |\n",
            "|    policy_gradient_loss | -0.0156      |\n",
            "|    std                  | 5.25         |\n",
            "|    value_loss           | 0.163        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 185         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 878         |\n",
            "|    time_elapsed         | 4309        |\n",
            "|    total_timesteps      | 1798144     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008216042 |\n",
            "|    clip_fraction        | 0.0481      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.3       |\n",
            "|    explained_variance   | 0.897       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 8770        |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    std                  | 5.28        |\n",
            "|    value_loss           | 0.119       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1800000, episode_reward=274.34 +/- 0.64\n",
            "Episode length: 819.80 +/- 5.04\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 820         |\n",
            "|    mean_reward          | 274         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1800000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007731879 |\n",
            "|    clip_fraction        | 0.0705      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.3       |\n",
            "|    explained_variance   | 0.894       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0798      |\n",
            "|    n_updates            | 8780        |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    std                  | 5.3         |\n",
            "|    value_loss           | 0.409       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 760      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 879      |\n",
            "|    time_elapsed    | 4318     |\n",
            "|    total_timesteps | 1800192  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 769         |\n",
            "|    ep_rew_mean          | 182         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 880         |\n",
            "|    time_elapsed         | 4321        |\n",
            "|    total_timesteps      | 1802240     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009272507 |\n",
            "|    clip_fraction        | 0.0709      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.3       |\n",
            "|    explained_variance   | 0.898       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0344     |\n",
            "|    n_updates            | 8790        |\n",
            "|    policy_gradient_loss | -0.0153     |\n",
            "|    std                  | 5.29        |\n",
            "|    value_loss           | 0.238       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 761         |\n",
            "|    ep_rew_mean          | 178         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 881         |\n",
            "|    time_elapsed         | 4325        |\n",
            "|    total_timesteps      | 1804288     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008560233 |\n",
            "|    clip_fraction        | 0.0867      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.3       |\n",
            "|    explained_variance   | 0.336       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.123      |\n",
            "|    n_updates            | 8800        |\n",
            "|    policy_gradient_loss | -0.015      |\n",
            "|    std                  | 5.3         |\n",
            "|    value_loss           | 0.0564      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 769          |\n",
            "|    ep_rew_mean          | 182          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 882          |\n",
            "|    time_elapsed         | 4328         |\n",
            "|    total_timesteps      | 1806336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061424505 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.3        |\n",
            "|    explained_variance   | 0.881        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.127       |\n",
            "|    n_updates            | 8810         |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    std                  | 5.32         |\n",
            "|    value_loss           | 0.0904       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 185         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 883         |\n",
            "|    time_elapsed         | 4332        |\n",
            "|    total_timesteps      | 1808384     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008113928 |\n",
            "|    clip_fraction        | 0.0701      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.3       |\n",
            "|    explained_variance   | 0.938       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.105      |\n",
            "|    n_updates            | 8820        |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    std                  | 5.37        |\n",
            "|    value_loss           | 0.121       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1810000, episode_reward=175.67 +/- 126.02\n",
            "Episode length: 691.60 +/- 221.24\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 692         |\n",
            "|    mean_reward          | 176         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1810000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009413358 |\n",
            "|    clip_fraction        | 0.0888      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.455       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.109      |\n",
            "|    n_updates            | 8830        |\n",
            "|    policy_gradient_loss | -0.018      |\n",
            "|    std                  | 5.37        |\n",
            "|    value_loss           | 0.0512      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 777      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    fps             | 417      |\n",
            "|    iterations      | 884      |\n",
            "|    time_elapsed    | 4340     |\n",
            "|    total_timesteps | 1810432  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 786         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 885         |\n",
            "|    time_elapsed         | 4344        |\n",
            "|    total_timesteps      | 1812480     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008771195 |\n",
            "|    clip_fraction        | 0.0579      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.913       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0376     |\n",
            "|    n_updates            | 8840        |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    std                  | 5.4         |\n",
            "|    value_loss           | 0.345       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 184         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 886         |\n",
            "|    time_elapsed         | 4348        |\n",
            "|    total_timesteps      | 1814528     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008405775 |\n",
            "|    clip_fraction        | 0.0807      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.908       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.1        |\n",
            "|    n_updates            | 8850        |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    std                  | 5.42        |\n",
            "|    value_loss           | 0.159       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 777         |\n",
            "|    ep_rew_mean          | 184         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 887         |\n",
            "|    time_elapsed         | 4351        |\n",
            "|    total_timesteps      | 1816576     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006312389 |\n",
            "|    clip_fraction        | 0.0415      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.839       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00333    |\n",
            "|    n_updates            | 8860        |\n",
            "|    policy_gradient_loss | -0.0126     |\n",
            "|    std                  | 5.44        |\n",
            "|    value_loss           | 0.361       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 777         |\n",
            "|    ep_rew_mean          | 184         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 888         |\n",
            "|    time_elapsed         | 4354        |\n",
            "|    total_timesteps      | 1818624     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009999668 |\n",
            "|    clip_fraction        | 0.0824      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.378       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0698     |\n",
            "|    n_updates            | 8870        |\n",
            "|    policy_gradient_loss | -0.014      |\n",
            "|    std                  | 5.42        |\n",
            "|    value_loss           | 0.18        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1820000, episode_reward=243.40 +/- 57.65\n",
            "Episode length: 806.40 +/- 56.64\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 806         |\n",
            "|    mean_reward          | 243         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1820000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007977722 |\n",
            "|    clip_fraction        | 0.061       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.0309      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 8880        |\n",
            "|    policy_gradient_loss | -0.016      |\n",
            "|    std                  | 5.41        |\n",
            "|    value_loss           | 0.0676      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 776      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    fps             | 417      |\n",
            "|    iterations      | 889      |\n",
            "|    time_elapsed    | 4364     |\n",
            "|    total_timesteps | 1820672  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 775         |\n",
            "|    ep_rew_mean          | 184         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 890         |\n",
            "|    time_elapsed         | 4368        |\n",
            "|    total_timesteps      | 1822720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008998007 |\n",
            "|    clip_fraction        | 0.0818      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | -0.00399    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.132      |\n",
            "|    n_updates            | 8890        |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    std                  | 5.39        |\n",
            "|    value_loss           | 0.0589      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 186         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 891         |\n",
            "|    time_elapsed         | 4372        |\n",
            "|    total_timesteps      | 1824768     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009548452 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.285       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.133      |\n",
            "|    n_updates            | 8900        |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    std                  | 5.39        |\n",
            "|    value_loss           | 0.0552      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 186         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 892         |\n",
            "|    time_elapsed         | 4376        |\n",
            "|    total_timesteps      | 1826816     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011530194 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.369       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0896     |\n",
            "|    n_updates            | 8910        |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    std                  | 5.42        |\n",
            "|    value_loss           | 0.0792      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 774          |\n",
            "|    ep_rew_mean          | 185          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 417          |\n",
            "|    iterations           | 893          |\n",
            "|    time_elapsed         | 4380         |\n",
            "|    total_timesteps      | 1828864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0094568385 |\n",
            "|    clip_fraction        | 0.0838       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.4        |\n",
            "|    explained_variance   | 0.154        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.124       |\n",
            "|    n_updates            | 8920         |\n",
            "|    policy_gradient_loss | -0.0178      |\n",
            "|    std                  | 5.42         |\n",
            "|    value_loss           | 0.0741       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1830000, episode_reward=105.70 +/- 138.16\n",
            "Episode length: 528.20 +/- 237.40\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 528          |\n",
            "|    mean_reward          | 106          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1830000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071336776 |\n",
            "|    clip_fraction        | 0.0604       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.4        |\n",
            "|    explained_variance   | 0.726        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0734      |\n",
            "|    n_updates            | 8930         |\n",
            "|    policy_gradient_loss | -0.0172      |\n",
            "|    std                  | 5.43         |\n",
            "|    value_loss           | 0.248        |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 766      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    fps             | 417      |\n",
            "|    iterations      | 894      |\n",
            "|    time_elapsed    | 4388     |\n",
            "|    total_timesteps | 1830912  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 772         |\n",
            "|    ep_rew_mean          | 184         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 895         |\n",
            "|    time_elapsed         | 4392        |\n",
            "|    total_timesteps      | 1832960     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008195438 |\n",
            "|    clip_fraction        | 0.0563      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.912       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.122      |\n",
            "|    n_updates            | 8940        |\n",
            "|    policy_gradient_loss | -0.0181     |\n",
            "|    std                  | 5.45        |\n",
            "|    value_loss           | 0.114       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 771         |\n",
            "|    ep_rew_mean          | 184         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 896         |\n",
            "|    time_elapsed         | 4396        |\n",
            "|    total_timesteps      | 1835008     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008896769 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.857       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0669     |\n",
            "|    n_updates            | 8950        |\n",
            "|    policy_gradient_loss | -0.0147     |\n",
            "|    std                  | 5.44        |\n",
            "|    value_loss           | 0.34        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 782         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 897         |\n",
            "|    time_elapsed         | 4401        |\n",
            "|    total_timesteps      | 1837056     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009137652 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | -0.143      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.131      |\n",
            "|    n_updates            | 8960        |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    std                  | 5.45        |\n",
            "|    value_loss           | 0.0586      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 782         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 898         |\n",
            "|    time_elapsed         | 4405        |\n",
            "|    total_timesteps      | 1839104     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008729478 |\n",
            "|    clip_fraction        | 0.0703      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.4       |\n",
            "|    explained_variance   | 0.888       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.105      |\n",
            "|    n_updates            | 8970        |\n",
            "|    policy_gradient_loss | -0.0158     |\n",
            "|    std                  | 5.48        |\n",
            "|    value_loss           | 0.209       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1840000, episode_reward=273.12 +/- 1.65\n",
            "Episode length: 829.40 +/- 18.85\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 829         |\n",
            "|    mean_reward          | 273         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1840000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006509809 |\n",
            "|    clip_fraction        | 0.0469      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | -0.145      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.105      |\n",
            "|    n_updates            | 8980        |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    std                  | 5.48        |\n",
            "|    value_loss           | 0.116       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 782      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 899      |\n",
            "|    time_elapsed    | 4416     |\n",
            "|    total_timesteps | 1841152  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 784         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 900         |\n",
            "|    time_elapsed         | 4420        |\n",
            "|    total_timesteps      | 1843200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007865847 |\n",
            "|    clip_fraction        | 0.0783      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.41        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 8990        |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    std                  | 5.49        |\n",
            "|    value_loss           | 0.0534      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 784         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 901         |\n",
            "|    time_elapsed         | 4425        |\n",
            "|    total_timesteps      | 1845248     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008926513 |\n",
            "|    clip_fraction        | 0.0761      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.819       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.113      |\n",
            "|    n_updates            | 9000        |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    std                  | 5.51        |\n",
            "|    value_loss           | 0.227       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 785         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 902         |\n",
            "|    time_elapsed         | 4430        |\n",
            "|    total_timesteps      | 1847296     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010915425 |\n",
            "|    clip_fraction        | 0.0979      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.38        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.12       |\n",
            "|    n_updates            | 9010        |\n",
            "|    policy_gradient_loss | -0.0192     |\n",
            "|    std                  | 5.5         |\n",
            "|    value_loss           | 0.0539      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 785         |\n",
            "|    ep_rew_mean          | 188         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 903         |\n",
            "|    time_elapsed         | 4434        |\n",
            "|    total_timesteps      | 1849344     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009058374 |\n",
            "|    clip_fraction        | 0.0807      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.538       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.12       |\n",
            "|    n_updates            | 9020        |\n",
            "|    policy_gradient_loss | -0.0181     |\n",
            "|    std                  | 5.52        |\n",
            "|    value_loss           | 0.0627      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1850000, episode_reward=272.64 +/- 0.93\n",
            "Episode length: 832.80 +/- 7.05\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 833         |\n",
            "|    mean_reward          | 273         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1850000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010709055 |\n",
            "|    clip_fraction        | 0.0886      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.369       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.117      |\n",
            "|    n_updates            | 9030        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 5.54        |\n",
            "|    value_loss           | 0.0701      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 785      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 904      |\n",
            "|    time_elapsed    | 4445     |\n",
            "|    total_timesteps | 1851392  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 785         |\n",
            "|    ep_rew_mean          | 189         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 905         |\n",
            "|    time_elapsed         | 4449        |\n",
            "|    total_timesteps      | 1853440     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010674215 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.512       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.102      |\n",
            "|    n_updates            | 9040        |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    std                  | 5.57        |\n",
            "|    value_loss           | 0.0714      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 784         |\n",
            "|    ep_rew_mean          | 189         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 906         |\n",
            "|    time_elapsed         | 4454        |\n",
            "|    total_timesteps      | 1855488     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011201767 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.398       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.12       |\n",
            "|    n_updates            | 9050        |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    std                  | 5.58        |\n",
            "|    value_loss           | 0.057       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 782         |\n",
            "|    ep_rew_mean          | 189         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 907         |\n",
            "|    time_elapsed         | 4458        |\n",
            "|    total_timesteps      | 1857536     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006994094 |\n",
            "|    clip_fraction        | 0.0516      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.5       |\n",
            "|    explained_variance   | 0.823       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.105      |\n",
            "|    n_updates            | 9060        |\n",
            "|    policy_gradient_loss | -0.0112     |\n",
            "|    std                  | 5.63        |\n",
            "|    value_loss           | 0.125       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 781         |\n",
            "|    ep_rew_mean          | 189         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 908         |\n",
            "|    time_elapsed         | 4461        |\n",
            "|    total_timesteps      | 1859584     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010388357 |\n",
            "|    clip_fraction        | 0.0704      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.6       |\n",
            "|    explained_variance   | 0.825       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 9070        |\n",
            "|    policy_gradient_loss | -0.0147     |\n",
            "|    std                  | 5.66        |\n",
            "|    value_loss           | 0.167       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1860000, episode_reward=273.47 +/- 1.34\n",
            "Episode length: 825.00 +/- 12.03\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 825          |\n",
            "|    mean_reward          | 273          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1860000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069304146 |\n",
            "|    clip_fraction        | 0.0491       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.6        |\n",
            "|    explained_variance   | 0.0719       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.113       |\n",
            "|    n_updates            | 9080         |\n",
            "|    policy_gradient_loss | -0.0131      |\n",
            "|    std                  | 5.66         |\n",
            "|    value_loss           | 0.0703       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 782      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 909      |\n",
            "|    time_elapsed    | 4472     |\n",
            "|    total_timesteps | 1861632  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 187         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 910         |\n",
            "|    time_elapsed         | 4475        |\n",
            "|    total_timesteps      | 1863680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009062154 |\n",
            "|    clip_fraction        | 0.0846      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.6       |\n",
            "|    explained_variance   | 0.49        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.123      |\n",
            "|    n_updates            | 9090        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 5.65        |\n",
            "|    value_loss           | 0.0631      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 187         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 911         |\n",
            "|    time_elapsed         | 4480        |\n",
            "|    total_timesteps      | 1865728     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007358303 |\n",
            "|    clip_fraction        | 0.0662      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.6       |\n",
            "|    explained_variance   | 0.895       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0992     |\n",
            "|    n_updates            | 9100        |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    std                  | 5.68        |\n",
            "|    value_loss           | 0.12        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 778        |\n",
            "|    ep_rew_mean          | 187        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 416        |\n",
            "|    iterations           | 912        |\n",
            "|    time_elapsed         | 4484       |\n",
            "|    total_timesteps      | 1867776    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00939741 |\n",
            "|    clip_fraction        | 0.0782     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -12.6      |\n",
            "|    explained_variance   | 0.3        |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.121     |\n",
            "|    n_updates            | 9110       |\n",
            "|    policy_gradient_loss | -0.0141    |\n",
            "|    std                  | 5.7        |\n",
            "|    value_loss           | 0.0602     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 778         |\n",
            "|    ep_rew_mean          | 187         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 913         |\n",
            "|    time_elapsed         | 4488        |\n",
            "|    total_timesteps      | 1869824     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009548763 |\n",
            "|    clip_fraction        | 0.0752      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.6       |\n",
            "|    explained_variance   | 0.286       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.116      |\n",
            "|    n_updates            | 9120        |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    std                  | 5.71        |\n",
            "|    value_loss           | 0.076       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1870000, episode_reward=272.34 +/- 1.55\n",
            "Episode length: 834.60 +/- 13.79\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 835          |\n",
            "|    mean_reward          | 272          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1870000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0101424325 |\n",
            "|    clip_fraction        | 0.0854       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.6        |\n",
            "|    explained_variance   | 0.244        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.125       |\n",
            "|    n_updates            | 9130         |\n",
            "|    policy_gradient_loss | -0.0148      |\n",
            "|    std                  | 5.71         |\n",
            "|    value_loss           | 0.0559       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 786      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    fps             | 416      |\n",
            "|    iterations      | 914      |\n",
            "|    time_elapsed    | 4498     |\n",
            "|    total_timesteps | 1871872  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 786         |\n",
            "|    ep_rew_mean          | 191         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 915         |\n",
            "|    time_elapsed         | 4502        |\n",
            "|    total_timesteps      | 1873920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007198207 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.6       |\n",
            "|    explained_variance   | 0.542       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.126      |\n",
            "|    n_updates            | 9140        |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    std                  | 5.73        |\n",
            "|    value_loss           | 0.0668      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 797         |\n",
            "|    ep_rew_mean          | 196         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 916         |\n",
            "|    time_elapsed         | 4505        |\n",
            "|    total_timesteps      | 1875968     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009850649 |\n",
            "|    clip_fraction        | 0.0886      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.6       |\n",
            "|    explained_variance   | 0.287       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.115      |\n",
            "|    n_updates            | 9150        |\n",
            "|    policy_gradient_loss | -0.0135     |\n",
            "|    std                  | 5.75        |\n",
            "|    value_loss           | 0.0788      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 796          |\n",
            "|    ep_rew_mean          | 196          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 917          |\n",
            "|    time_elapsed         | 4510         |\n",
            "|    total_timesteps      | 1878016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069221356 |\n",
            "|    clip_fraction        | 0.0568       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.7        |\n",
            "|    explained_variance   | 0.276        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.109       |\n",
            "|    n_updates            | 9160         |\n",
            "|    policy_gradient_loss | -0.0121      |\n",
            "|    std                  | 5.78         |\n",
            "|    value_loss           | 0.0551       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1880000, episode_reward=274.39 +/- 0.81\n",
            "Episode length: 811.20 +/- 3.76\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 811         |\n",
            "|    mean_reward          | 274         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1880000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006584748 |\n",
            "|    clip_fraction        | 0.0611      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.7       |\n",
            "|    explained_variance   | 0.922       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.115      |\n",
            "|    n_updates            | 9170        |\n",
            "|    policy_gradient_loss | -0.0164     |\n",
            "|    std                  | 5.8         |\n",
            "|    value_loss           | 0.108       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 790      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 918      |\n",
            "|    time_elapsed    | 4519     |\n",
            "|    total_timesteps | 1880064  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 801         |\n",
            "|    ep_rew_mean          | 198         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 919         |\n",
            "|    time_elapsed         | 4524        |\n",
            "|    total_timesteps      | 1882112     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008978069 |\n",
            "|    clip_fraction        | 0.0806      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.7       |\n",
            "|    explained_variance   | 0.904       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0925     |\n",
            "|    n_updates            | 9180        |\n",
            "|    policy_gradient_loss | -0.0165     |\n",
            "|    std                  | 5.81        |\n",
            "|    value_loss           | 0.14        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 815         |\n",
            "|    ep_rew_mean          | 205         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 920         |\n",
            "|    time_elapsed         | 4528        |\n",
            "|    total_timesteps      | 1884160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007879994 |\n",
            "|    clip_fraction        | 0.0594      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.7       |\n",
            "|    explained_variance   | 0.15        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.091      |\n",
            "|    n_updates            | 9190        |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 5.8         |\n",
            "|    value_loss           | 0.0591      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 823         |\n",
            "|    ep_rew_mean          | 209         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 921         |\n",
            "|    time_elapsed         | 4532        |\n",
            "|    total_timesteps      | 1886208     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009944711 |\n",
            "|    clip_fraction        | 0.0758      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.7       |\n",
            "|    explained_variance   | -0.02       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.116      |\n",
            "|    n_updates            | 9200        |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    std                  | 5.81        |\n",
            "|    value_loss           | 0.0658      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 832         |\n",
            "|    ep_rew_mean          | 212         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 922         |\n",
            "|    time_elapsed         | 4536        |\n",
            "|    total_timesteps      | 1888256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008541863 |\n",
            "|    clip_fraction        | 0.0643      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.7       |\n",
            "|    explained_variance   | 0.309       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.103      |\n",
            "|    n_updates            | 9210        |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 5.84        |\n",
            "|    value_loss           | 0.0527      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1890000, episode_reward=273.23 +/- 1.12\n",
            "Episode length: 824.00 +/- 7.29\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 824         |\n",
            "|    mean_reward          | 273         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1890000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008219528 |\n",
            "|    clip_fraction        | 0.0832      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.7       |\n",
            "|    explained_variance   | 0.413       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.118      |\n",
            "|    n_updates            | 9220        |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    std                  | 5.87        |\n",
            "|    value_loss           | 0.0566      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 832      |\n",
            "|    ep_rew_mean     | 212      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 923      |\n",
            "|    time_elapsed    | 4546     |\n",
            "|    total_timesteps | 1890304  |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 838        |\n",
            "|    ep_rew_mean          | 213        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 415        |\n",
            "|    iterations           | 924        |\n",
            "|    time_elapsed         | 4550       |\n",
            "|    total_timesteps      | 1892352    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00806707 |\n",
            "|    clip_fraction        | 0.0706     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -12.7      |\n",
            "|    explained_variance   | 0.596      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.14      |\n",
            "|    n_updates            | 9230       |\n",
            "|    policy_gradient_loss | -0.0148    |\n",
            "|    std                  | 5.9        |\n",
            "|    value_loss           | 0.0701     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 846         |\n",
            "|    ep_rew_mean          | 217         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 925         |\n",
            "|    time_elapsed         | 4554        |\n",
            "|    total_timesteps      | 1894400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007505233 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.903       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 9240        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 5.93        |\n",
            "|    value_loss           | 0.138       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 845          |\n",
            "|    ep_rew_mean          | 217          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 926          |\n",
            "|    time_elapsed         | 4557         |\n",
            "|    total_timesteps      | 1896448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075261015 |\n",
            "|    clip_fraction        | 0.0594       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.179        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.108       |\n",
            "|    n_updates            | 9250         |\n",
            "|    policy_gradient_loss | -0.0142      |\n",
            "|    std                  | 5.92         |\n",
            "|    value_loss           | 0.0962       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 847          |\n",
            "|    ep_rew_mean          | 219          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 927          |\n",
            "|    time_elapsed         | 4562         |\n",
            "|    total_timesteps      | 1898496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073972885 |\n",
            "|    clip_fraction        | 0.0689       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.102        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.123       |\n",
            "|    n_updates            | 9260         |\n",
            "|    policy_gradient_loss | -0.0134      |\n",
            "|    std                  | 5.94         |\n",
            "|    value_loss           | 0.0737       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1900000, episode_reward=270.87 +/- 1.20\n",
            "Episode length: 841.00 +/- 12.35\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 841         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1900000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009952954 |\n",
            "|    clip_fraction        | 0.0781      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.41        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.123      |\n",
            "|    n_updates            | 9270        |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    std                  | 5.93        |\n",
            "|    value_loss           | 0.0576      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 855      |\n",
            "|    ep_rew_mean     | 222      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 928      |\n",
            "|    time_elapsed    | 4571     |\n",
            "|    total_timesteps | 1900544  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 860          |\n",
            "|    ep_rew_mean          | 224          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 929          |\n",
            "|    time_elapsed         | 4575         |\n",
            "|    total_timesteps      | 1902592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064707836 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.8        |\n",
            "|    explained_variance   | 0.485        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.114       |\n",
            "|    n_updates            | 9280         |\n",
            "|    policy_gradient_loss | -0.0132      |\n",
            "|    std                  | 5.94         |\n",
            "|    value_loss           | 0.118        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 867         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 930         |\n",
            "|    time_elapsed         | 4579        |\n",
            "|    total_timesteps      | 1904640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009126451 |\n",
            "|    clip_fraction        | 0.0799      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.318       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.124      |\n",
            "|    n_updates            | 9290        |\n",
            "|    policy_gradient_loss | -0.0161     |\n",
            "|    std                  | 5.96        |\n",
            "|    value_loss           | 0.0665      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 867         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 931         |\n",
            "|    time_elapsed         | 4582        |\n",
            "|    total_timesteps      | 1906688     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008308822 |\n",
            "|    clip_fraction        | 0.0753      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.397       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.121      |\n",
            "|    n_updates            | 9300        |\n",
            "|    policy_gradient_loss | -0.0144     |\n",
            "|    std                  | 5.98        |\n",
            "|    value_loss           | 0.0797      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 866         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 932         |\n",
            "|    time_elapsed         | 4587        |\n",
            "|    total_timesteps      | 1908736     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008436446 |\n",
            "|    clip_fraction        | 0.0641      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.484       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 9310        |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    std                  | 5.98        |\n",
            "|    value_loss           | 0.0584      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1910000, episode_reward=271.40 +/- 0.81\n",
            "Episode length: 839.60 +/- 7.55\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 840         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1910000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012231795 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.345       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.13       |\n",
            "|    n_updates            | 9320        |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    std                  | 5.99        |\n",
            "|    value_loss           | 0.0585      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 866      |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 933      |\n",
            "|    time_elapsed    | 4596     |\n",
            "|    total_timesteps | 1910784  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 866         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 934         |\n",
            "|    time_elapsed         | 4601        |\n",
            "|    total_timesteps      | 1912832     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010253112 |\n",
            "|    clip_fraction        | 0.0905      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.447       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.135      |\n",
            "|    n_updates            | 9330        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 6           |\n",
            "|    value_loss           | 0.0425      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 866         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 935         |\n",
            "|    time_elapsed         | 4605        |\n",
            "|    total_timesteps      | 1914880     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009686662 |\n",
            "|    clip_fraction        | 0.0686      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.311       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.136      |\n",
            "|    n_updates            | 9340        |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    std                  | 6.02        |\n",
            "|    value_loss           | 0.0811      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 865         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 936         |\n",
            "|    time_elapsed         | 4608        |\n",
            "|    total_timesteps      | 1916928     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008679854 |\n",
            "|    clip_fraction        | 0.0685      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.8       |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.121      |\n",
            "|    n_updates            | 9350        |\n",
            "|    policy_gradient_loss | -0.0138     |\n",
            "|    std                  | 6.01        |\n",
            "|    value_loss           | 0.0553      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 868         |\n",
            "|    ep_rew_mean          | 230         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 937         |\n",
            "|    time_elapsed         | 4612        |\n",
            "|    total_timesteps      | 1918976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008847229 |\n",
            "|    clip_fraction        | 0.0891      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.308       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.12       |\n",
            "|    n_updates            | 9360        |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    std                  | 6.08        |\n",
            "|    value_loss           | 0.0621      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1920000, episode_reward=270.54 +/- 1.44\n",
            "Episode length: 848.40 +/- 12.83\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 848         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1920000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006934009 |\n",
            "|    clip_fraction        | 0.039       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.779       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 9370        |\n",
            "|    policy_gradient_loss | -0.0121     |\n",
            "|    std                  | 6.11        |\n",
            "|    value_loss           | 0.113       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 875      |\n",
            "|    ep_rew_mean     | 233      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 938      |\n",
            "|    time_elapsed    | 4621     |\n",
            "|    total_timesteps | 1921024  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 879          |\n",
            "|    ep_rew_mean          | 236          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 939          |\n",
            "|    time_elapsed         | 4625         |\n",
            "|    total_timesteps      | 1923072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075373743 |\n",
            "|    clip_fraction        | 0.0568       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 0.387        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.13        |\n",
            "|    n_updates            | 9380         |\n",
            "|    policy_gradient_loss | -0.0148      |\n",
            "|    std                  | 6.09         |\n",
            "|    value_loss           | 0.0631       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 867         |\n",
            "|    ep_rew_mean          | 231         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 940         |\n",
            "|    time_elapsed         | 4629        |\n",
            "|    total_timesteps      | 1925120     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009849038 |\n",
            "|    clip_fraction        | 0.0993      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.427       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.129      |\n",
            "|    n_updates            | 9390        |\n",
            "|    policy_gradient_loss | -0.0133     |\n",
            "|    std                  | 6.1         |\n",
            "|    value_loss           | 0.0533      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 871         |\n",
            "|    ep_rew_mean          | 233         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 941         |\n",
            "|    time_elapsed         | 4633        |\n",
            "|    total_timesteps      | 1927168     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007876134 |\n",
            "|    clip_fraction        | 0.0506      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -12.9       |\n",
            "|    explained_variance   | 0.886       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.122      |\n",
            "|    n_updates            | 9400        |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    std                  | 6.13        |\n",
            "|    value_loss           | 0.117       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 872          |\n",
            "|    ep_rew_mean          | 233          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 942          |\n",
            "|    time_elapsed         | 4636         |\n",
            "|    total_timesteps      | 1929216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0106806755 |\n",
            "|    clip_fraction        | 0.0805       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -12.9        |\n",
            "|    explained_variance   | 0.454        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.13        |\n",
            "|    n_updates            | 9410         |\n",
            "|    policy_gradient_loss | -0.0134      |\n",
            "|    std                  | 6.19         |\n",
            "|    value_loss           | 0.053        |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1930000, episode_reward=271.49 +/- 1.08\n",
            "Episode length: 839.40 +/- 8.96\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 839          |\n",
            "|    mean_reward          | 271          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 1930000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065180752 |\n",
            "|    clip_fraction        | 0.0506       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13          |\n",
            "|    explained_variance   | 0.614        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.116       |\n",
            "|    n_updates            | 9420         |\n",
            "|    policy_gradient_loss | -0.0155      |\n",
            "|    std                  | 6.2          |\n",
            "|    value_loss           | 0.0573       |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 871      |\n",
            "|    ep_rew_mean     | 233      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 943      |\n",
            "|    time_elapsed    | 4646     |\n",
            "|    total_timesteps | 1931264  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 873         |\n",
            "|    ep_rew_mean          | 235         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 944         |\n",
            "|    time_elapsed         | 4649        |\n",
            "|    total_timesteps      | 1933312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009481836 |\n",
            "|    clip_fraction        | 0.0896      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.505       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.129      |\n",
            "|    n_updates            | 9430        |\n",
            "|    policy_gradient_loss | -0.0175     |\n",
            "|    std                  | 6.21        |\n",
            "|    value_loss           | 0.0661      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 876         |\n",
            "|    ep_rew_mean          | 237         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 945         |\n",
            "|    time_elapsed         | 4653        |\n",
            "|    total_timesteps      | 1935360     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008323148 |\n",
            "|    clip_fraction        | 0.0757      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.319       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.131      |\n",
            "|    n_updates            | 9440        |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    std                  | 6.21        |\n",
            "|    value_loss           | 0.0585      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 875         |\n",
            "|    ep_rew_mean          | 237         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 946         |\n",
            "|    time_elapsed         | 4657        |\n",
            "|    total_timesteps      | 1937408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007021864 |\n",
            "|    clip_fraction        | 0.0549      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.283       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.119      |\n",
            "|    n_updates            | 9450        |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    std                  | 6.23        |\n",
            "|    value_loss           | 0.0565      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 873         |\n",
            "|    ep_rew_mean          | 238         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 947         |\n",
            "|    time_elapsed         | 4661        |\n",
            "|    total_timesteps      | 1939456     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010845408 |\n",
            "|    clip_fraction        | 0.0976      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.395       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.134      |\n",
            "|    n_updates            | 9460        |\n",
            "|    policy_gradient_loss | -0.0185     |\n",
            "|    std                  | 6.22        |\n",
            "|    value_loss           | 0.0822      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1940000, episode_reward=220.88 +/- 103.03\n",
            "Episode length: 744.20 +/- 170.83\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 744         |\n",
            "|    mean_reward          | 221         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1940000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008155864 |\n",
            "|    clip_fraction        | 0.0755      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.425       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.112      |\n",
            "|    n_updates            | 9470        |\n",
            "|    policy_gradient_loss | -0.0141     |\n",
            "|    std                  | 6.25        |\n",
            "|    value_loss           | 0.0547      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 872      |\n",
            "|    ep_rew_mean     | 238      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 948      |\n",
            "|    time_elapsed    | 4670     |\n",
            "|    total_timesteps | 1941504  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 857         |\n",
            "|    ep_rew_mean          | 230         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 949         |\n",
            "|    time_elapsed         | 4673        |\n",
            "|    total_timesteps      | 1943552     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008067783 |\n",
            "|    clip_fraction        | 0.0635      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.398       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.129      |\n",
            "|    n_updates            | 9480        |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    std                  | 6.28        |\n",
            "|    value_loss           | 0.0663      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 866          |\n",
            "|    ep_rew_mean          | 234          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 950          |\n",
            "|    time_elapsed         | 4677         |\n",
            "|    total_timesteps      | 1945600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067897253 |\n",
            "|    clip_fraction        | 0.0519       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13          |\n",
            "|    explained_variance   | 0.898        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0976      |\n",
            "|    n_updates            | 9490         |\n",
            "|    policy_gradient_loss | -0.0158      |\n",
            "|    std                  | 6.3          |\n",
            "|    value_loss           | 0.282        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 865         |\n",
            "|    ep_rew_mean          | 234         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 951         |\n",
            "|    time_elapsed         | 4680        |\n",
            "|    total_timesteps      | 1947648     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009093002 |\n",
            "|    clip_fraction        | 0.079       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.122       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.116      |\n",
            "|    n_updates            | 9500        |\n",
            "|    policy_gradient_loss | -0.0136     |\n",
            "|    std                  | 6.29        |\n",
            "|    value_loss           | 0.11        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 865         |\n",
            "|    ep_rew_mean          | 234         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 952         |\n",
            "|    time_elapsed         | 4684        |\n",
            "|    total_timesteps      | 1949696     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008721642 |\n",
            "|    clip_fraction        | 0.0779      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.846       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.112      |\n",
            "|    n_updates            | 9510        |\n",
            "|    policy_gradient_loss | -0.0153     |\n",
            "|    std                  | 6.31        |\n",
            "|    value_loss           | 0.14        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1950000, episode_reward=270.84 +/- 1.04\n",
            "Episode length: 841.60 +/- 9.85\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 842         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1950000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007025361 |\n",
            "|    clip_fraction        | 0.0697      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.517       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.139      |\n",
            "|    n_updates            | 9520        |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    std                  | 6.33        |\n",
            "|    value_loss           | 0.0702      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 865      |\n",
            "|    ep_rew_mean     | 234      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 953      |\n",
            "|    time_elapsed    | 4693     |\n",
            "|    total_timesteps | 1951744  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 867         |\n",
            "|    ep_rew_mean          | 235         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 954         |\n",
            "|    time_elapsed         | 4697        |\n",
            "|    total_timesteps      | 1953792     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007314287 |\n",
            "|    clip_fraction        | 0.0736      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.522       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.112      |\n",
            "|    n_updates            | 9530        |\n",
            "|    policy_gradient_loss | -0.0162     |\n",
            "|    std                  | 6.32        |\n",
            "|    value_loss           | 0.085       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 849         |\n",
            "|    ep_rew_mean          | 228         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 955         |\n",
            "|    time_elapsed         | 4701        |\n",
            "|    total_timesteps      | 1955840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011209941 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.359       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.105      |\n",
            "|    n_updates            | 9540        |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    std                  | 6.34        |\n",
            "|    value_loss           | 0.0783      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 849          |\n",
            "|    ep_rew_mean          | 228          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 956          |\n",
            "|    time_elapsed         | 4704         |\n",
            "|    total_timesteps      | 1957888      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046938034 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13          |\n",
            "|    explained_variance   | 0.827        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0824      |\n",
            "|    n_updates            | 9550         |\n",
            "|    policy_gradient_loss | -0.0119      |\n",
            "|    std                  | 6.38         |\n",
            "|    value_loss           | 0.172        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 844          |\n",
            "|    ep_rew_mean          | 225          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 957          |\n",
            "|    time_elapsed         | 4708         |\n",
            "|    total_timesteps      | 1959936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053233765 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13          |\n",
            "|    explained_variance   | 0.25         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 9560         |\n",
            "|    policy_gradient_loss | -0.0121      |\n",
            "|    std                  | 6.32         |\n",
            "|    value_loss           | 0.105        |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1960000, episode_reward=246.85 +/- 48.87\n",
            "Episode length: 824.80 +/- 23.73\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 825         |\n",
            "|    mean_reward          | 247         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1960000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011679591 |\n",
            "|    clip_fraction        | 0.0861      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.808       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.111      |\n",
            "|    n_updates            | 9570        |\n",
            "|    policy_gradient_loss | -0.0177     |\n",
            "|    std                  | 6.34        |\n",
            "|    value_loss           | 0.214       |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 844      |\n",
            "|    ep_rew_mean     | 225      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 958      |\n",
            "|    time_elapsed    | 4717     |\n",
            "|    total_timesteps | 1961984  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 844         |\n",
            "|    ep_rew_mean          | 225         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 959         |\n",
            "|    time_elapsed         | 4720        |\n",
            "|    total_timesteps      | 1964032     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008573718 |\n",
            "|    clip_fraction        | 0.0687      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.0665      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.137      |\n",
            "|    n_updates            | 9580        |\n",
            "|    policy_gradient_loss | -0.0145     |\n",
            "|    std                  | 6.34        |\n",
            "|    value_loss           | 0.0703      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 848         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 960         |\n",
            "|    time_elapsed         | 4725        |\n",
            "|    total_timesteps      | 1966080     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007511357 |\n",
            "|    clip_fraction        | 0.0677      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.12        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.125      |\n",
            "|    n_updates            | 9590        |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    std                  | 6.35        |\n",
            "|    value_loss           | 0.0641      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 847          |\n",
            "|    ep_rew_mean          | 227          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 961          |\n",
            "|    time_elapsed         | 4728         |\n",
            "|    total_timesteps      | 1968128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077844393 |\n",
            "|    clip_fraction        | 0.0415       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13          |\n",
            "|    explained_variance   | 0.338        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.129       |\n",
            "|    n_updates            | 9600         |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    std                  | 6.35         |\n",
            "|    value_loss           | 0.0535       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1970000, episode_reward=271.29 +/- 0.95\n",
            "Episode length: 838.60 +/- 10.31\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 839       |\n",
            "|    mean_reward          | 271       |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 1970000   |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0087664 |\n",
            "|    clip_fraction        | 0.0673    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -13       |\n",
            "|    explained_variance   | 0.309     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | -0.108    |\n",
            "|    n_updates            | 9610      |\n",
            "|    policy_gradient_loss | -0.0146   |\n",
            "|    std                  | 6.32      |\n",
            "|    value_loss           | 0.0551    |\n",
            "---------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 852      |\n",
            "|    ep_rew_mean     | 230      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 962      |\n",
            "|    time_elapsed    | 4738     |\n",
            "|    total_timesteps | 1970176  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 852         |\n",
            "|    ep_rew_mean          | 230         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 963         |\n",
            "|    time_elapsed         | 4742        |\n",
            "|    total_timesteps      | 1972224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008247793 |\n",
            "|    clip_fraction        | 0.071       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.469       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.129      |\n",
            "|    n_updates            | 9620        |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    std                  | 6.31        |\n",
            "|    value_loss           | 0.0667      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 853         |\n",
            "|    ep_rew_mean          | 230         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 964         |\n",
            "|    time_elapsed         | 4745        |\n",
            "|    total_timesteps      | 1974272     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009044963 |\n",
            "|    clip_fraction        | 0.072       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13         |\n",
            "|    explained_variance   | 0.43        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.103      |\n",
            "|    n_updates            | 9630        |\n",
            "|    policy_gradient_loss | -0.0147     |\n",
            "|    std                  | 6.36        |\n",
            "|    value_loss           | 0.0556      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 852          |\n",
            "|    ep_rew_mean          | 229          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 965          |\n",
            "|    time_elapsed         | 4749         |\n",
            "|    total_timesteps      | 1976320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0078481855 |\n",
            "|    clip_fraction        | 0.0723       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13.1        |\n",
            "|    explained_variance   | 0.509        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.146       |\n",
            "|    n_updates            | 9640         |\n",
            "|    policy_gradient_loss | -0.013       |\n",
            "|    std                  | 6.39         |\n",
            "|    value_loss           | 0.0576       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 852         |\n",
            "|    ep_rew_mean          | 229         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 966         |\n",
            "|    time_elapsed         | 4753        |\n",
            "|    total_timesteps      | 1978368     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009847252 |\n",
            "|    clip_fraction        | 0.0726      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.1       |\n",
            "|    explained_variance   | 0.926       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.137      |\n",
            "|    n_updates            | 9650        |\n",
            "|    policy_gradient_loss | -0.0178     |\n",
            "|    std                  | 6.43        |\n",
            "|    value_loss           | 0.0712      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=1980000, episode_reward=271.42 +/- 0.71\n",
            "Episode length: 837.20 +/- 6.24\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 837         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1980000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009189866 |\n",
            "|    clip_fraction        | 0.0764      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.1       |\n",
            "|    explained_variance   | 0.27        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0963     |\n",
            "|    n_updates            | 9660        |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    std                  | 6.46        |\n",
            "|    value_loss           | 0.0934      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 851      |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 967      |\n",
            "|    time_elapsed    | 4762     |\n",
            "|    total_timesteps | 1980416  |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 854          |\n",
            "|    ep_rew_mean          | 231          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 968          |\n",
            "|    time_elapsed         | 4766         |\n",
            "|    total_timesteps      | 1982464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071029584 |\n",
            "|    clip_fraction        | 0.0567       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13.1        |\n",
            "|    explained_variance   | 0.534        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.119       |\n",
            "|    n_updates            | 9670         |\n",
            "|    policy_gradient_loss | -0.0123      |\n",
            "|    std                  | 6.5          |\n",
            "|    value_loss           | 0.0439       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 854         |\n",
            "|    ep_rew_mean          | 231         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 969         |\n",
            "|    time_elapsed         | 4769        |\n",
            "|    total_timesteps      | 1984512     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011358349 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.1       |\n",
            "|    explained_variance   | 0.328       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.12       |\n",
            "|    n_updates            | 9680        |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    std                  | 6.48        |\n",
            "|    value_loss           | 0.0557      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 844         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 970         |\n",
            "|    time_elapsed         | 4773        |\n",
            "|    total_timesteps      | 1986560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008900748 |\n",
            "|    clip_fraction        | 0.0604      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.1       |\n",
            "|    explained_variance   | 0.432       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.131      |\n",
            "|    n_updates            | 9690        |\n",
            "|    policy_gradient_loss | -0.0128     |\n",
            "|    std                  | 6.47        |\n",
            "|    value_loss           | 0.057       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 844          |\n",
            "|    ep_rew_mean          | 227          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 971          |\n",
            "|    time_elapsed         | 4777         |\n",
            "|    total_timesteps      | 1988608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0087547265 |\n",
            "|    clip_fraction        | 0.0737       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13.1        |\n",
            "|    explained_variance   | 0.813        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0937      |\n",
            "|    n_updates            | 9700         |\n",
            "|    policy_gradient_loss | -0.0168      |\n",
            "|    std                  | 6.52         |\n",
            "|    value_loss           | 0.14         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1990000, episode_reward=271.81 +/- 0.83\n",
            "Episode length: 834.20 +/- 7.03\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 834         |\n",
            "|    mean_reward          | 272         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1990000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007812606 |\n",
            "|    clip_fraction        | 0.0644      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.2       |\n",
            "|    explained_variance   | 0.552       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.104      |\n",
            "|    n_updates            | 9710        |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    std                  | 6.54        |\n",
            "|    value_loss           | 0.0634      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 844      |\n",
            "|    ep_rew_mean     | 227      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 972      |\n",
            "|    time_elapsed    | 4785     |\n",
            "|    total_timesteps | 1990656  |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 844         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 415         |\n",
            "|    iterations           | 973         |\n",
            "|    time_elapsed         | 4790        |\n",
            "|    total_timesteps      | 1992704     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007497496 |\n",
            "|    clip_fraction        | 0.0704      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.2       |\n",
            "|    explained_variance   | 0.577       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.129      |\n",
            "|    n_updates            | 9720        |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    std                  | 6.52        |\n",
            "|    value_loss           | 0.0366      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 845          |\n",
            "|    ep_rew_mean          | 227          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 974          |\n",
            "|    time_elapsed         | 4793         |\n",
            "|    total_timesteps      | 1994752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069034584 |\n",
            "|    clip_fraction        | 0.0534       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13.1        |\n",
            "|    explained_variance   | 0.447        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.125       |\n",
            "|    n_updates            | 9730         |\n",
            "|    policy_gradient_loss | -0.0147      |\n",
            "|    std                  | 6.49         |\n",
            "|    value_loss           | 0.0759       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 846         |\n",
            "|    ep_rew_mean          | 227         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 416         |\n",
            "|    iterations           | 975         |\n",
            "|    time_elapsed         | 4797        |\n",
            "|    total_timesteps      | 1996800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011288816 |\n",
            "|    clip_fraction        | 0.0903      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.1       |\n",
            "|    explained_variance   | 0.563       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.124      |\n",
            "|    n_updates            | 9740        |\n",
            "|    policy_gradient_loss | -0.0155     |\n",
            "|    std                  | 6.54        |\n",
            "|    value_loss           | 0.0836      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 846          |\n",
            "|    ep_rew_mean          | 227          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 976          |\n",
            "|    time_elapsed         | 4800         |\n",
            "|    total_timesteps      | 1998848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076394337 |\n",
            "|    clip_fraction        | 0.06         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -13.2        |\n",
            "|    explained_variance   | 0.582        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 9750         |\n",
            "|    policy_gradient_loss | -0.0142      |\n",
            "|    std                  | 6.57         |\n",
            "|    value_loss           | 0.0631       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=2000000, episode_reward=271.31 +/- 0.61\n",
            "Episode length: 836.40 +/- 3.72\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 836         |\n",
            "|    mean_reward          | 271         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 2000000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008569585 |\n",
            "|    clip_fraction        | 0.0685      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -13.2       |\n",
            "|    explained_variance   | 0.485       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.138      |\n",
            "|    n_updates            | 9760        |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    std                  | 6.59        |\n",
            "|    value_loss           | 0.0535      |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 846      |\n",
            "|    ep_rew_mean     | 227      |\n",
            "| time/              |          |\n",
            "|    fps             | 415      |\n",
            "|    iterations      | 977      |\n",
            "|    time_elapsed    | 4809     |\n",
            "|    total_timesteps | 2000896  |\n",
            "---------------------------------\n",
            "Best score achieved: 276.4700076\n",
            "Completed training PPO model for seed: 0\n",
            "Total training time: 4810.32 seconds\n",
            "Test seed: 1, Total reward: [-31.030771]\n",
            "Test seed: 2, Total reward: [-30.889923]\n",
            "Test seed: 3, Total reward: [-32.798424]\n",
            "Test seed: 4, Total reward: [-32.290028]\n",
            "Test seed: 5, Total reward: [-31.812227]\n",
            "Average reward across test seeds: -31.764272689819336, Std Dev: 0.7281068563461304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dRvqjC9yUStQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}