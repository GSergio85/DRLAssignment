{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo8dJGDjLT9u",
        "outputId": "93e4c1d8-a4f2-4fbc-d432-c1015cb29e2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting mujoco>=2.3.3 (from gymnasium)\n",
            "  Downloading mujoco-3.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.31.6)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio>=2.14.1->gymnasium) (9.4.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium) (1.7.0)\n",
            "Collecting glfw (from mujoco>=2.3.3->gymnasium)\n",
            "  Downloading glfw-2.7.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.3->gymnasium) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco>=2.3.3->gymnasium) (3.19.2)\n",
            "Installing collected packages: glfw, farama-notifications, gymnasium, mujoco\n",
            "Successfully installed farama-notifications-0.0.4 glfw-2.7.0 gymnasium-0.29.1 mujoco-3.1.6\n",
            "Collecting shimmy>=0.2.1\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy>=0.2.1) (1.25.2)\n",
            "Collecting gymnasium>=1.0.0a1 (from shimmy>=0.2.1)\n",
            "  Downloading gymnasium-1.0.0a2-py3-none-any.whl (954 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.3/954.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=0.2.1) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=0.2.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a1->shimmy>=0.2.1) (0.0.4)\n",
            "Installing collected packages: gymnasium, shimmy\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.29.1\n",
            "    Uninstalling gymnasium-0.29.1:\n",
            "      Successfully uninstalled gymnasium-0.29.1\n",
            "Successfully installed gymnasium-1.0.0a2 shimmy-2.0.0\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0a2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "\u001b[31mERROR: Invalid requirement: '-'\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: mujoco in /usr/local/lib/python3.10/dist-packages (3.1.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.7.0)\n",
            "Requirement already satisfied: glfw in /usr/local/lib/python3.10/dist-packages (from mujoco) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.25.2)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco) (3.1.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (4.12.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->mujoco) (3.19.2)\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium<0.30,>=0.28.1 (from stable-baselines3)\n",
            "  Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.15.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, gymnasium, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0a2\n",
            "    Uninstalling gymnasium-1.0.0a2:\n",
            "      Successfully uninstalled gymnasium-1.0.0a2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "shimmy 2.0.0 requires gymnasium>=1.0.0a1, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 stable-baselines3-2.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium gymnasium[mujoco]\n",
        "!pip install 'shimmy>=0.2.1'\n",
        "!pip install gymnasium\n",
        "!pip install -- upgrade stable - baselines3\n",
        "!pip install mujoco\n",
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3 gym tensorboard\n",
        "!apt-get install swig\n",
        "!pip install box2d\n",
        "!pip install gym[box2d]\n",
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HlfdNC-MB-Z",
        "outputId": "932aad92-5f18-432e-ad23-d0e7cb88bd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.15.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (1,371 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting box2d\n",
            "  Downloading Box2D-2.3.2.tar.gz (427 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.9/427.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d\n",
            "  Building wheel for box2d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d: filename=Box2D-2.3.2-cp310-cp310-linux_x86_64.whl size=2367285 sha256=4ed213428b2a2544b04291722b0e73d70ba0e060114aa08128958a07a8f7e63c\n",
            "  Stored in directory: /root/.cache/pip/wheels/eb/cb/be/e663f3ce9aba6580611c0febaf7cd3cf7603f87047de2a52f9\n",
            "Successfully built box2d\n",
            "Installing collected packages: box2d\n",
            "Successfully installed box2d-2.3.2\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym[box2d]) (0.0.8)\n",
            "Collecting box2d-py==2.3.5 (from gym[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.0 (from gym[box2d])\n",
            "  Downloading pygame-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.* (from gym[box2d])\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2349145 sha256=4e38a8f4da47d0bf23d687a1ff7620c6dfc1b71ac0784021f8cf7162442e8ebb\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: swig, box2d-py, pygame\n",
            "  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.5.2\n",
            "    Uninstalling pygame-2.5.2:\n",
            "      Successfully uninstalled pygame-2.5.2\n",
            "Successfully installed box2d-py-2.3.5 pygame-2.1.0 swig-4.2.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 2: off-policy SAC model\n",
        "import time\n",
        "import numpy as np\n",
        "import gym\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import VecNormalize, DummyVecEnv\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "\n",
        "def create_bipedalwalker_env(seed=None):\n",
        "    env = make_vec_env('BipedalWalker-v3', n_envs=1, seed=seed)\n",
        "    env = VecNormalize(env, norm_obs=True, norm_reward=True)\n",
        "    return env\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    seed = 0\n",
        "    set_random_seed(seed)\n",
        "\n",
        "    print(f\"Training SAC model with seed: {seed}\")\n",
        "\n",
        "    #Create the environment\n",
        "    env = create_bipedalwalker_env(seed)\n",
        "\n",
        "    #Saving\n",
        "    env.save(f'BipedalWalker-v3_vecnormalize_seed_{seed}.pkl')\n",
        "\n",
        "    #Train the agent\n",
        "    model = SAC(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, gamma=0.99, buffer_size=1000000, batch_size=256,\n",
        "                tau=0.005, train_freq=1, gradient_steps=1, tensorboard_log=\"./tb_logs/\", seed=seed)\n",
        "\n",
        "    #Evaluate if the model reaches 300\n",
        "    callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
        "    eval_callback = EvalCallback(env, callback_on_new_best=callback_on_best, eval_freq=10000,\n",
        "                                 best_model_save_path='./logs/', log_path='./logs/', deterministic=True, render=False)\n",
        "\n",
        "    #Time the model\n",
        "    start_time = time.time()\n",
        "\n",
        "    #Training\n",
        "    total_timesteps = 2000000\n",
        "    model.learn(total_timesteps=total_timesteps, callback=eval_callback, tb_log_name=\"sac_bipedalwalker\")\n",
        "\n",
        "    #End timing when done\n",
        "    end_time = time.time()\n",
        "\n",
        "    #Calculate time\n",
        "    training_time = end_time - start_time\n",
        "\n",
        "    #Save the model\n",
        "    model.save(f'sac_bipedalwalker_seed_{seed}')\n",
        "\n",
        "    #Save VecNormalize statistics\n",
        "    env.save(f'BipedalWalker-v3_vecnormalize_seed_{seed}.pkl')\n",
        "\n",
        "    #Print the results\n",
        "    best_score = eval_callback.best_mean_reward\n",
        "    if best_score < 300:\n",
        "        print(f\"Best score achieved: {best_score}\")\n",
        "\n",
        "    print(f\"Completed training SAC model for seed: {seed}\")\n",
        "    print(f\"Training session for SAC took {training_time:.2f} seconds\")\n",
        "\n",
        "    #Test model on multiple seeds\n",
        "    test_seeds = [1, 2, 3, 4, 5]\n",
        "    test_results = []\n",
        "\n",
        "    for test_seed in test_seeds:\n",
        "        set_random_seed(test_seed)\n",
        "        test_env = create_bipedalwalker_env(test_seed)\n",
        "        obs = test_env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        while not done:\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, _ = test_env.step(action)\n",
        "            total_reward += reward\n",
        "        test_results.append(total_reward)\n",
        "        print(f\"Test seed: {test_seed}, Total reward: {total_reward}\")\n",
        "\n",
        "    print(f\"Average reward across test seeds: {np.mean(test_results)}, Std Dev: {np.std(test_results)}\")"
      ],
      "metadata": {
        "id": "kaVXqV9Sk9V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c73331f-a76c-41ee-a3cb-7412bb424033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training SAC model with seed: 0\n",
            "Using cuda device\n",
            "Logging to ./tb_logs/sac_bipedalwalker_1\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 462      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 22       |\n",
            "|    total_timesteps | 1850     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.9    |\n",
            "|    critic_loss     | 0.104    |\n",
            "|    ent_coef        | 0.592    |\n",
            "|    ent_coef_loss   | -3.47    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1749     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 458      |\n",
            "|    ep_rew_mean     | -107     |\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 78       |\n",
            "|    time_elapsed    | 46       |\n",
            "|    total_timesteps | 3664     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.1    |\n",
            "|    critic_loss     | 0.0863   |\n",
            "|    ent_coef        | 0.344    |\n",
            "|    ent_coef_loss   | -7.02    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3563     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 337      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 78       |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 4046     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.7    |\n",
            "|    critic_loss     | 0.496    |\n",
            "|    ent_coef        | 0.307    |\n",
            "|    ent_coef_loss   | -7.88    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3945     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 272      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 56       |\n",
            "|    total_timesteps | 4357     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -24.5    |\n",
            "|    critic_loss     | 0.0993   |\n",
            "|    ent_coef        | 0.28     |\n",
            "|    ent_coef_loss   | -8.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4256     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 312      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 80       |\n",
            "|    total_timesteps | 6240     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -25.5    |\n",
            "|    critic_loss     | 0.0826   |\n",
            "|    ent_coef        | 0.16     |\n",
            "|    ent_coef_loss   | -11.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6139     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 341      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 106      |\n",
            "|    total_timesteps | 8182     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -25      |\n",
            "|    critic_loss     | 0.104    |\n",
            "|    ent_coef        | 0.0909   |\n",
            "|    ent_coef_loss   | -14.5    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8081     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 315      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 114      |\n",
            "|    total_timesteps | 8812     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -23.9    |\n",
            "|    critic_loss     | 0.108    |\n",
            "|    ent_coef        | 0.0755   |\n",
            "|    ent_coef_loss   | -15      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8711     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-57.67 +/- 25.86\n",
            "Episode length: 1600.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.6e+03  |\n",
            "|    mean_reward     | -57.7    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -22.3    |\n",
            "|    critic_loss     | 0.112    |\n",
            "|    ent_coef        | 0.054    |\n",
            "|    ent_coef_loss   | -15.3    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9899     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 346      |\n",
            "|    ep_rew_mean     | -116     |\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 163      |\n",
            "|    total_timesteps | 11712    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20.4    |\n",
            "|    critic_loss     | 0.0972   |\n",
            "|    ent_coef        | 0.0339   |\n",
            "|    ent_coef_loss   | -15.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 11611    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 330      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 175      |\n",
            "|    total_timesteps | 12546    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20      |\n",
            "|    critic_loss     | 0.189    |\n",
            "|    ent_coef        | 0.0268   |\n",
            "|    ent_coef_loss   | -16.1    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12445    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 306      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 180      |\n",
            "|    total_timesteps | 12895    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -19.2    |\n",
            "|    critic_loss     | 0.132    |\n",
            "|    ent_coef        | 0.0243   |\n",
            "|    ent_coef_loss   | -15.3    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 12794    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 295      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 189      |\n",
            "|    total_timesteps | 13616    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -18.3    |\n",
            "|    critic_loss     | 0.149    |\n",
            "|    ent_coef        | 0.0199   |\n",
            "|    ent_coef_loss   | -14.9    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13515    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 352      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 242      |\n",
            "|    total_timesteps | 17565    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16      |\n",
            "|    critic_loss     | 0.0805   |\n",
            "|    ent_coef        | 0.00752  |\n",
            "|    ent_coef_loss   | -8.13    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 17464    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-50.42 +/- 3.28\n",
            "Episode length: 1600.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.6e+03  |\n",
            "|    mean_reward     | -50.4    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.4    |\n",
            "|    critic_loss     | 0.0434   |\n",
            "|    ent_coef        | 0.0044   |\n",
            "|    ent_coef_loss   | -4.92    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19899    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 429      |\n",
            "|    ep_rew_mean     | -118     |\n",
            "| time/              |          |\n",
            "|    episodes        | 52       |\n",
            "|    fps             | 70       |\n",
            "|    time_elapsed    | 336      |\n",
            "|    total_timesteps | 23788    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -12.4    |\n",
            "|    critic_loss     | 0.0321   |\n",
            "|    ent_coef        | 0.00351  |\n",
            "|    ent_coef_loss   | -1.46    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 23687    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 481      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 56       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 395      |\n",
            "|    total_timesteps | 28413    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.6    |\n",
            "|    critic_loss     | 0.0182   |\n",
            "|    ent_coef        | 0.00297  |\n",
            "|    ent_coef_loss   | -6.13    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 28312    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=-124.69 +/- 11.78\n",
            "Episode length: 466.40 +/- 580.75\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 466      |\n",
            "|    mean_reward     | -125     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.17    |\n",
            "|    critic_loss     | 0.0266   |\n",
            "|    ent_coef        | 0.00264  |\n",
            "|    ent_coef_loss   | 1.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 479      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 423      |\n",
            "|    total_timesteps | 30373    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -9.27    |\n",
            "|    critic_loss     | 0.0255   |\n",
            "|    ent_coef        | 0.00247  |\n",
            "|    ent_coef_loss   | -1       |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 30272    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 457      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 64       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 429      |\n",
            "|    total_timesteps | 30893    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.95    |\n",
            "|    critic_loss     | 0.0457   |\n",
            "|    ent_coef        | 0.00227  |\n",
            "|    ent_coef_loss   | -0.521   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 30792    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 459      |\n",
            "|    ep_rew_mean     | -122     |\n",
            "| time/              |          |\n",
            "|    episodes        | 68       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 455      |\n",
            "|    total_timesteps | 32865    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.8     |\n",
            "|    critic_loss     | 0.0496   |\n",
            "|    ent_coef        | 0.00202  |\n",
            "|    ent_coef_loss   | 2.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 32764    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 447      |\n",
            "|    ep_rew_mean     | -120     |\n",
            "| time/              |          |\n",
            "|    episodes        | 72       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 467      |\n",
            "|    total_timesteps | 33802    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.79    |\n",
            "|    critic_loss     | 0.0314   |\n",
            "|    ent_coef        | 0.00188  |\n",
            "|    ent_coef_loss   | 0.236    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 33701    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 434      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 76       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 478      |\n",
            "|    total_timesteps | 34650    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.32    |\n",
            "|    critic_loss     | 0.0329   |\n",
            "|    ent_coef        | 0.00172  |\n",
            "|    ent_coef_loss   | 0.269    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 34549    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 419      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 485      |\n",
            "|    total_timesteps | 35171    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -7.19    |\n",
            "|    critic_loss     | 0.0319   |\n",
            "|    ent_coef        | 0.00166  |\n",
            "|    ent_coef_loss   | 0.526    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 35070    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 424      |\n",
            "|    ep_rew_mean     | -119     |\n",
            "| time/              |          |\n",
            "|    episodes        | 84       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 512      |\n",
            "|    total_timesteps | 37280    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -6.29    |\n",
            "|    critic_loss     | 0.0254   |\n",
            "|    ent_coef        | 0.00156  |\n",
            "|    ent_coef_loss   | -0.881   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 37179    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=-56.63 +/- 5.64\n",
            "Episode length: 1600.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.6e+03  |\n",
            "|    mean_reward     | -56.6    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -5.39    |\n",
            "|    critic_loss     | 0.0253   |\n",
            "|    ent_coef        | 0.0015   |\n",
            "|    ent_coef_loss   | 2.53     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 39899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 465      |\n",
            "|    ep_rew_mean     | -117     |\n",
            "| time/              |          |\n",
            "|    episodes        | 88       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 600      |\n",
            "|    total_timesteps | 43200    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -4.66    |\n",
            "|    critic_loss     | 0.0129   |\n",
            "|    ent_coef        | 0.00136  |\n",
            "|    ent_coef_loss   | -3.97    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 43099    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 484      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 92       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 645      |\n",
            "|    total_timesteps | 46815    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.97    |\n",
            "|    critic_loss     | 0.0132   |\n",
            "|    ent_coef        | 0.00133  |\n",
            "|    ent_coef_loss   | -0.534   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 46714    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 483      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 96       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 669      |\n",
            "|    total_timesteps | 48699    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.58    |\n",
            "|    critic_loss     | 0.0176   |\n",
            "|    ent_coef        | 0.0015   |\n",
            "|    ent_coef_loss   | -0.0326  |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 48598    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=-85.01 +/- 8.64\n",
            "Episode length: 284.80 +/- 107.25\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 285      |\n",
            "|    mean_reward     | -85      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -3.42    |\n",
            "|    critic_loss     | 0.025    |\n",
            "|    ent_coef        | 0.00145  |\n",
            "|    ent_coef_loss   | -4.32    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 49899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 484      |\n",
            "|    ep_rew_mean     | -115     |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 696      |\n",
            "|    total_timesteps | 50693    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.96    |\n",
            "|    critic_loss     | 0.0139   |\n",
            "|    ent_coef        | 0.0013   |\n",
            "|    ent_coef_loss   | 3.16     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 50592    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 476      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    episodes        | 104      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 709      |\n",
            "|    total_timesteps | 51757    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.9     |\n",
            "|    critic_loss     | 0.0315   |\n",
            "|    ent_coef        | 0.0011   |\n",
            "|    ent_coef_loss   | -2.82    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 51656    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 513      |\n",
            "|    ep_rew_mean     | -111     |\n",
            "| time/              |          |\n",
            "|    episodes        | 108      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 780      |\n",
            "|    total_timesteps | 57337    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -2.3     |\n",
            "|    critic_loss     | 0.00678  |\n",
            "|    ent_coef        | 0.00093  |\n",
            "|    ent_coef_loss   | 1.7      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 57236    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=0.57 +/- 68.27\n",
            "Episode length: 881.40 +/- 473.51\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 881      |\n",
            "|    mean_reward     | 0.574    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.85    |\n",
            "|    critic_loss     | 0.00759  |\n",
            "|    ent_coef        | 0.000827 |\n",
            "|    ent_coef_loss   | -2.28    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 59899    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 549      |\n",
            "|    ep_rew_mean     | -105     |\n",
            "| time/              |          |\n",
            "|    episodes        | 112      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 840      |\n",
            "|    total_timesteps | 61600    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.66    |\n",
            "|    critic_loss     | 0.00858  |\n",
            "|    ent_coef        | 0.000758 |\n",
            "|    ent_coef_loss   | -0.0682  |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 61499    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 555      |\n",
            "|    ep_rew_mean     | -104     |\n",
            "| time/              |          |\n",
            "|    episodes        | 116      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 852      |\n",
            "|    total_timesteps | 62533    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.63    |\n",
            "|    critic_loss     | 0.00798  |\n",
            "|    ent_coef        | 0.000724 |\n",
            "|    ent_coef_loss   | -2.39    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 62432    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 569      |\n",
            "|    ep_rew_mean     | -102     |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 893      |\n",
            "|    total_timesteps | 65775    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.38    |\n",
            "|    critic_loss     | 0.0051   |\n",
            "|    ent_coef        | 0.000707 |\n",
            "|    ent_coef_loss   | -1.51    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 65674    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 564      |\n",
            "|    ep_rew_mean     | -101     |\n",
            "| time/              |          |\n",
            "|    episodes        | 124      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 912      |\n",
            "|    total_timesteps | 67288    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -1.18    |\n",
            "|    critic_loss     | 0.0104   |\n",
            "|    ent_coef        | 0.000719 |\n",
            "|    ent_coef_loss   | -1.3     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 67187    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=-26.79 +/- 52.40\n",
            "Episode length: 885.00 +/- 447.93\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 885      |\n",
            "|    mean_reward     | -26.8    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.894   |\n",
            "|    critic_loss     | 0.00752  |\n",
            "|    ent_coef        | 0.000702 |\n",
            "|    ent_coef_loss   | -0.647   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 69899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 589      |\n",
            "|    ep_rew_mean     | -97.3    |\n",
            "| time/              |          |\n",
            "|    episodes        | 128      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 958      |\n",
            "|    total_timesteps | 70354    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.79    |\n",
            "|    critic_loss     | 0.00848  |\n",
            "|    ent_coef        | 0.000692 |\n",
            "|    ent_coef_loss   | 2.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 70253    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 603      |\n",
            "|    ep_rew_mean     | -88.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 132      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1006     |\n",
            "|    total_timesteps | 74076    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.569   |\n",
            "|    critic_loss     | 0.00887  |\n",
            "|    ent_coef        | 0.000685 |\n",
            "|    ent_coef_loss   | 0.0776   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 73975    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 641      |\n",
            "|    ep_rew_mean     | -77.8    |\n",
            "| time/              |          |\n",
            "|    episodes        | 136      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1064     |\n",
            "|    total_timesteps | 78648    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.727   |\n",
            "|    critic_loss     | 0.00784  |\n",
            "|    ent_coef        | 0.000716 |\n",
            "|    ent_coef_loss   | -0.704   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 78547    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=234.34 +/- 74.73\n",
            "Episode length: 1370.20 +/- 229.17\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.37e+03 |\n",
            "|    mean_reward     | 234      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.591   |\n",
            "|    critic_loss     | 0.00448  |\n",
            "|    ent_coef        | 0.000718 |\n",
            "|    ent_coef_loss   | 0.0641   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 79899    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 674      |\n",
            "|    ep_rew_mean     | -73      |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1139     |\n",
            "|    total_timesteps | 83683    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.436   |\n",
            "|    critic_loss     | 0.00523  |\n",
            "|    ent_coef        | 0.000717 |\n",
            "|    ent_coef_loss   | -0.472   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 83582    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 686      |\n",
            "|    ep_rew_mean     | -69.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 144      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1163     |\n",
            "|    total_timesteps | 85541    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.487   |\n",
            "|    critic_loss     | 0.00553  |\n",
            "|    ent_coef        | 0.000745 |\n",
            "|    ent_coef_loss   | -2.89    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 85440    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 674      |\n",
            "|    ep_rew_mean     | -62.4    |\n",
            "| time/              |          |\n",
            "|    episodes        | 148      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1198     |\n",
            "|    total_timesteps | 88290    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.565   |\n",
            "|    critic_loss     | 0.00429  |\n",
            "|    ent_coef        | 0.000764 |\n",
            "|    ent_coef_loss   | -0.621   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 88189    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=157.58 +/- 112.78\n",
            "Episode length: 1118.40 +/- 290.52\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.12e+03 |\n",
            "|    mean_reward     | 158      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.0914  |\n",
            "|    critic_loss     | 0.0071   |\n",
            "|    ent_coef        | 0.000764 |\n",
            "|    ent_coef_loss   | 2.58     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 89899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 633      |\n",
            "|    ep_rew_mean     | -58.5    |\n",
            "| time/              |          |\n",
            "|    episodes        | 152      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1231     |\n",
            "|    total_timesteps | 90294    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.354   |\n",
            "|    critic_loss     | 0.006    |\n",
            "|    ent_coef        | 0.000751 |\n",
            "|    ent_coef_loss   | 0.233    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 90193    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 638      |\n",
            "|    ep_rew_mean     | -41.7    |\n",
            "| time/              |          |\n",
            "|    episodes        | 156      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1296     |\n",
            "|    total_timesteps | 95441    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.362   |\n",
            "|    critic_loss     | 0.00536  |\n",
            "|    ent_coef        | 0.000722 |\n",
            "|    ent_coef_loss   | 0.367    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 95340    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=247.66 +/- 83.36\n",
            "Episode length: 1294.20 +/- 171.44\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.29e+03 |\n",
            "|    mean_reward     | 248      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.407   |\n",
            "|    critic_loss     | 0.00563  |\n",
            "|    ent_coef        | 0.000651 |\n",
            "|    ent_coef_loss   | 1.21     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 99899    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 670      |\n",
            "|    ep_rew_mean     | -24.2    |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1377     |\n",
            "|    total_timesteps | 101200   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.557   |\n",
            "|    critic_loss     | 0.00283  |\n",
            "|    ent_coef        | 0.000691 |\n",
            "|    ent_coef_loss   | -0.756   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 101099   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 713      |\n",
            "|    ep_rew_mean     | -9.37    |\n",
            "| time/              |          |\n",
            "|    episodes        | 164      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1438     |\n",
            "|    total_timesteps | 105982   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.591   |\n",
            "|    critic_loss     | 0.00246  |\n",
            "|    ent_coef        | 0.000689 |\n",
            "|    ent_coef_loss   | -3.42    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 105881   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=110000, episode_reward=260.01 +/- 64.59\n",
            "Episode length: 1039.80 +/- 105.67\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.04e+03 |\n",
            "|    mean_reward     | 260      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 110000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.581   |\n",
            "|    critic_loss     | 0.00249  |\n",
            "|    ent_coef        | 0.000661 |\n",
            "|    ent_coef_loss   | 4.64     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 109899   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 739      |\n",
            "|    ep_rew_mean     | 6.97     |\n",
            "| time/              |          |\n",
            "|    episodes        | 168      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1511     |\n",
            "|    total_timesteps | 111167   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.617   |\n",
            "|    critic_loss     | 0.00576  |\n",
            "|    ent_coef        | 0.000656 |\n",
            "|    ent_coef_loss   | -1.8     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 111066   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 765      |\n",
            "|    ep_rew_mean     | 17.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 172      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1555     |\n",
            "|    total_timesteps | 114640   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.612   |\n",
            "|    critic_loss     | 0.00418  |\n",
            "|    ent_coef        | 0.000614 |\n",
            "|    ent_coef_loss   | -0.825   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 114539   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 795      |\n",
            "|    ep_rew_mean     | 31.3     |\n",
            "| time/              |          |\n",
            "|    episodes        | 176      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1604     |\n",
            "|    total_timesteps | 118540   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.568   |\n",
            "|    critic_loss     | 0.00194  |\n",
            "|    ent_coef        | 0.000604 |\n",
            "|    ent_coef_loss   | 1.08     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 118439   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=298.42 +/- 1.22\n",
            "Episode length: 1086.80 +/- 22.09\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.09e+03 |\n",
            "|    mean_reward     | 298      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 120000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.742   |\n",
            "|    critic_loss     | 0.0011   |\n",
            "|    ent_coef        | 0.000634 |\n",
            "|    ent_coef_loss   | -2.94    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 119899   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 825      |\n",
            "|    ep_rew_mean     | 43.5     |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1656     |\n",
            "|    total_timesteps | 122050   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.584   |\n",
            "|    critic_loss     | 0.0033   |\n",
            "|    ent_coef        | 0.000617 |\n",
            "|    ent_coef_loss   | 2.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 121949   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 844      |\n",
            "|    ep_rew_mean     | 58.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 184      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1706     |\n",
            "|    total_timesteps | 126057   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.688   |\n",
            "|    critic_loss     | 0.00121  |\n",
            "|    ent_coef        | 0.000609 |\n",
            "|    ent_coef_loss   | 0.941    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 125956   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 828      |\n",
            "|    ep_rew_mean     | 70       |\n",
            "| time/              |          |\n",
            "|    episodes        | 188      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1753     |\n",
            "|    total_timesteps | 129751   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.736   |\n",
            "|    critic_loss     | 0.00219  |\n",
            "|    ent_coef        | 0.000582 |\n",
            "|    ent_coef_loss   | 0.25     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 129650   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=130000, episode_reward=244.56 +/- 113.87\n",
            "Episode length: 928.40 +/- 227.53\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 928      |\n",
            "|    mean_reward     | 245      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 130000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.742   |\n",
            "|    critic_loss     | 0.00231  |\n",
            "|    ent_coef        | 0.000593 |\n",
            "|    ent_coef_loss   | 2.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 129899   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 830      |\n",
            "|    ep_rew_mean     | 82.8     |\n",
            "| time/              |          |\n",
            "|    episodes        | 192      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 1810     |\n",
            "|    total_timesteps | 133767   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.819   |\n",
            "|    critic_loss     | 0.0012   |\n",
            "|    ent_coef        | 0.0006   |\n",
            "|    ent_coef_loss   | 1.6      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 133666   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 844      |\n",
            "|    ep_rew_mean     | 95.2     |\n",
            "| time/              |          |\n",
            "|    episodes        | 196      |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 1851     |\n",
            "|    total_timesteps | 137028   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.831   |\n",
            "|    critic_loss     | 0.00125  |\n",
            "|    ent_coef        | 0.000581 |\n",
            "|    ent_coef_loss   | -0.603   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 136927   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=140000, episode_reward=304.90 +/- 0.86\n",
            "Episode length: 1018.00 +/- 29.91\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1.02e+03 |\n",
            "|    mean_reward     | 305      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 140000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.876   |\n",
            "|    critic_loss     | 0.00182  |\n",
            "|    ent_coef        | 0.000597 |\n",
            "|    ent_coef_loss   | 0.154    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 139899   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "Stopping training because the mean reward 304.90  is above the threshold 300\n",
            "Completed training SAC model for seed: 0\n",
            "Training session for SAC took 1896.19 seconds\n",
            "Test seed: 1, Total reward: [-33.455303]\n",
            "Test seed: 2, Total reward: [-29.682957]\n",
            "Test seed: 3, Total reward: [-33.74459]\n",
            "Test seed: 4, Total reward: [-26.148197]\n",
            "Test seed: 5, Total reward: [-36.220898]\n",
            "Average reward across test seeds: -31.850391387939453, Std Dev: 3.534907341003418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mFEDgfSiU74v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}